<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>11个开发人员必备AI聊天界面 | LangChat Docs</title>
    <meta name="description" content="LangChat Project Document">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.wFIoVwSX.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.Cjw_v9nb.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.BoyLCJnS.js">
    <link rel="modulepreload" href="/assets/chunks/framework.ByciF0Oj.js">
    <link rel="modulepreload" href="/assets/docs_other_top11-ai-chat-ui-for-developers.md.CSnixW_I.lean.js">
    <link rel="shortcut icon" href="/favicon.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-ed470ed6><!--[--><!--]--><!--[--><span tabindex="-1" data-v-f444f753></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-f444f753>Skip to content</a><!--]--><!----><header class="VPNav" data-v-ed470ed6 data-v-f09ebc71><div class="VPNavBar" data-v-f09ebc71 data-v-1044928a><div class="wrapper" data-v-1044928a><div class="container" data-v-1044928a><div class="title" data-v-1044928a><div class="VPNavBarTitle has-sidebar" data-v-1044928a data-v-c494e956><a class="title" href="/" data-v-c494e956><!--[--><!--]--><!----><span data-v-c494e956>LangChat Docs</span><!--[--><!--]--></a></div></div><div class="content" data-v-1044928a><div class="content-body" data-v-1044928a><!--[--><!--]--><div class="VPNavBarSearch search" data-v-1044928a><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-1044928a data-v-51f1f89a><span id="main-nav-aria-label" class="visually-hidden" data-v-51f1f89a> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-51f1f89a data-v-2ebde2b3><!--[--><span data-v-2ebde2b3>LangChat</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/docs/exercise/langchat-deepseek-r1.html" tabindex="0" data-v-51f1f89a data-v-2ebde2b3><!--[--><span data-v-2ebde2b3>LangChat文档</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-51f1f89a data-v-e2cb7df8><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-e2cb7df8><span class="text" data-v-e2cb7df8><!----><span data-v-e2cb7df8>在线预览</span><span class="vpi-chevron-down text-icon" data-v-e2cb7df8></span></span></button><div class="menu" data-v-e2cb7df8><div class="VPMenu" data-v-e2cb7df8 data-v-7750fdeb><div class="items" data-v-7750fdeb><!--[--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="https://langchat.cn/" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat官网</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="http://backend.langchat.cn/" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat后台预览</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="http://llm.langchat.cn" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat LLM Ops</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="http://upms.langchat.cn" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat UPMS Ops</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-1044928a data-v-adf2275d><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-adf2275d data-v-4cc58f0d data-v-f45163c9><span class="check" data-v-f45163c9><span class="icon" data-v-f45163c9><!--[--><span class="vpi-sun sun" data-v-4cc58f0d></span><span class="vpi-moon moon" data-v-4cc58f0d></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-1044928a data-v-17ef9bfb data-v-34ec2aad><!--[--><a class="VPSocialLink no-icon" href="https://github.com/TyCoding/langchat" aria-label="github" target="_blank" rel="noopener" data-v-34ec2aad data-v-6953ab1f><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-1044928a data-v-a84198a3 data-v-e2cb7df8><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-e2cb7df8><span class="vpi-more-horizontal icon" data-v-e2cb7df8></span></button><div class="menu" data-v-e2cb7df8><div class="VPMenu" data-v-e2cb7df8 data-v-7750fdeb><!----><!--[--><!--[--><!----><div class="group" data-v-a84198a3><div class="item appearance" data-v-a84198a3><p class="label" data-v-a84198a3>Appearance</p><div class="appearance-action" data-v-a84198a3><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-a84198a3 data-v-4cc58f0d data-v-f45163c9><span class="check" data-v-f45163c9><span class="icon" data-v-f45163c9><!--[--><span class="vpi-sun sun" data-v-4cc58f0d></span><span class="vpi-moon moon" data-v-4cc58f0d></span><!--]--></span></span></button></div></div></div><div class="group" data-v-a84198a3><div class="item social-links" data-v-a84198a3><div class="VPSocialLinks social-links-list" data-v-a84198a3 data-v-34ec2aad><!--[--><a class="VPSocialLink no-icon" href="https://github.com/TyCoding/langchat" aria-label="github" target="_blank" rel="noopener" data-v-34ec2aad data-v-6953ab1f><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-1044928a data-v-5598f36f><span class="container" data-v-5598f36f><span class="top" data-v-5598f36f></span><span class="middle" data-v-5598f36f></span><span class="bottom" data-v-5598f36f></span></span></button></div></div></div></div><div class="divider" data-v-1044928a><div class="divider-line" data-v-1044928a></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-ed470ed6 data-v-d1ebcfd2><div class="container" data-v-d1ebcfd2><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-d1ebcfd2><span class="vpi-align-left menu-icon" data-v-d1ebcfd2></span><span class="menu-text" data-v-d1ebcfd2>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-d1ebcfd2 data-v-8683af8e><button data-v-8683af8e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-ed470ed6 data-v-b5cecb30><div class="curtain" data-v-b5cecb30></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-b5cecb30><span class="visually-hidden" id="sidebar-aria-label" data-v-b5cecb30> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>LangChat实战</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/exercise/langchat-deepseek-r1.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1实战</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/exercise/oss-minio.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>使用Minio作为OSS</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/exercise/rag.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>LLM-RAG基础概念</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>LangChat配置</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/introduce.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>LangChat介绍</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/environment.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>环境准备</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/getting-started.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>快速开始</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/login.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>登录LangChat</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/models.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>模型配置</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/models-proxy.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>模型代理</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/knowledge.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>知识库</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/questions.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>常见问题</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>LangChat部署</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/deploy/deploy.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>LangChat部署教程</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0 has-active" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>推荐阅读</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/chunking-strategies.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>大模型RAG中的分块策略</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/claude-3-7-sonnet.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>Claude 3.7 Sonnet强势来袭</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-architecture-and-training.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek R1架构和训练过程图解</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-distilled-models.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1蒸馏模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-reasoning-capabilities-analysis.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1的推理能力分析</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-tuning.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1微调指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/distill-deepseek-r1-into-your-model.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>蒸馏DeepSeek-R1到自己的模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/guide-getting-started-with-cursor-and-deepseek-r1.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>Cursor + DeepSeek R1 使用指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/hardware-guide-for-llm-training-and-fine-tuning.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>大模型训练/微调硬件指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/markitdown-a-deep-dive.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>MarkItDown深入研究</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/reasoning-modes-vs-other-ai-models.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>推理模型 vs. 其他AI模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/the-ai-web-search-landscape.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>AI搜索引擎生态全景</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/top8-on-premise-plans-for-deepseek-r1.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>8个DeepSeek-R1私有化部署方案</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/top11-ai-chat-ui-for-developers.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>11个开发人员必备AI聊天界面</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/vllm-llm-local-inference-library.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>vLLM 大模型本地推理库</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/vllm-ollama-comprehensive-comparison.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>vLLM/ollama综合对比</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/vllm-vs-ollama.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>VLLM vs. Ollama</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-ed470ed6 data-v-ee4370c0><div class="VPDoc has-sidebar has-aside" data-v-ee4370c0 data-v-479a6568><!--[--><!--]--><div class="container" data-v-479a6568><div class="aside" data-v-479a6568><div class="aside-curtain" data-v-479a6568></div><div class="aside-container" data-v-479a6568><div class="aside-content" data-v-479a6568><div class="VPDocAside" data-v-479a6568 data-v-312359a6><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-312359a6 data-v-f9862b92><div class="content" data-v-f9862b92><div class="outline-marker" data-v-f9862b92></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f9862b92>On this page</div><ul class="VPDocOutlineItem root" data-v-f9862b92 data-v-316b2cab><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-312359a6></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-479a6568><div class="content-container" data-v-479a6568><!--[--><!--]--><main class="main" data-v-479a6568><div style="position:relative;" class="vp-doc _docs_other_top11-ai-chat-ui-for-developers" data-v-479a6568><div><h1 id="_11个开发人员必备ai聊天界面" tabindex="-1">11个开发人员必备AI聊天界面 <a class="header-anchor" href="#_11个开发人员必备ai聊天界面" aria-label="Permalink to &quot;11个开发人员必备AI聊天界面&quot;">​</a></h1><p>Google 正在变老，开发人员现在正在使用现代 AI 聊天工具来完成所有编程任务。</p><h3 id="关于langchat" tabindex="-1">关于LangChat <a class="header-anchor" href="#关于langchat" aria-label="Permalink to &quot;关于LangChat&quot;">​</a></h3><p><strong>LangChat</strong> 是Java生态下企业级AIGC项目解决方案，集成RBAC和AIGC大模型能力，帮助企业快速定制AI知识库、企业AI机器人。</p><p><strong>支持的AI大模型：</strong> Gitee AI / 阿里通义 / 百度千帆 / DeepSeek / 抖音豆包 / 智谱清言 / 零一万物 / 讯飞星火 / OpenAI / Gemini / Ollama / Azure / Claude 等大模型。</p><ul><li>官网地址：<a href="http://langchat.cn/" target="_blank" rel="noreferrer">http://langchat.cn/</a></li></ul><p><strong>开源地址：</strong></p><ul><li>Gitee：<a href="https://gitee.com/langchat/langchat" target="_blank" rel="noreferrer">https://gitee.com/langchat/langchat</a></li><li>Github：<a href="https://github.com/tycoding/langchat" target="_blank" rel="noreferrer">https://github.com/tycoding/langchat</a></li></ul><p><img src="http://cdn.tycoding.cn/docs/202502151026673.png" alt="iShot_2025-02-12_12.18.53" loading="lazy"></p><p>Google 正在变老，开发人员现在正在使用现代 AI 聊天工具来完成所有编程任务。</p><p>这是 11 个具有最佳 AI 聊天界面的开源项目的列表，可帮助你最大限度地提高工作效率。</p><p>让我们开始吧。</p><h2 id="_1、llmchat-最直观的一体化-ai-聊天界面" tabindex="-1">1、LLMChat - 最直观的一体化 AI 聊天界面 <a class="header-anchor" href="#_1、llmchat-最直观的一体化-ai-聊天界面" aria-label="Permalink to &quot;1、LLMChat - 最直观的一体化 AI 聊天界面&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-313.png" alt="img" loading="lazy"></p><p>我已经测试了所有工具，我相信<a href="https://llmchat.co/chat/" target="_blank" rel="noreferrer"> LLMChat </a>是最好的工具之一。</p><p>我特别喜欢这个，因为用户界面看起来很干净。 我甚至不需要教程就可以理解大多数东西。</p><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-329.png" alt="img" loading="lazy"></p><p>让我们看看一些使其功能强大 10 倍的功能。</p><ul><li>支持各种语言模型，包括 GPT 4o Mini、Ollama、Claude、Groq 和 lm studio（即将推出）。您也可以根据需要使用本地模型。如果您刚刚开始使用，他们会提供自己的免费模型。</li><li>我最喜欢的功能是他们提供了一个插件系统，包括函数调用功能，这使其更上一层楼。</li><li>你甚至可以为上下文附加图像。</li><li>它还会为你提供相关的搜索结果建议。</li><li>你还可以获得一个提示库，可以在其中找到预定义的提示或创建自己的提示。</li><li>他们的设置也有很多选项，例如可以导入/导出数据、启用 Whisper 语音转文本等等。</li><li>你还可以搜索对话，因此这是手动监视。它会更快，特别是如果你为对话创建自己的标题。</li><li>它使用浏览器内的 IndexedDB 在本地安全地存储数据，以实现更快的访问和隐私。阅读隐私政策。</li><li>他们计划推出一项名为 Knowledge Spaces 的功能，该功能将成为针对专业主题的自定义知识库。我很想看到它的实际应用！</li></ul><p>还需要什么？</p><p>它基于我最喜欢的技术堆栈构建，使用了 Next.js、TypeScript、Pglite、LangChain、Zustand、React Query、Supabase、Tailwind CSS、Framer Motion、Shadcn 和 Tiptap。</p><p>你可以在<a href="https://llmchat.co/chat/" target="_blank" rel="noreferrer"> llmchat.co/chat</a> 查看演示并分享你的反馈。</p><p>LLMChat 是开源的，在<a href="https://github.com/trendy-design/llmchat" target="_blank" rel="noreferrer"> GitHub</a> 上有 133 颗星。它处于早期阶段，但它会发展得非常快。</p><h2 id="_2、open-webui-最受欢迎的-ai-界面-离线运行" tabindex="-1">2、Open WebUI - 最受欢迎的 AI 界面，离线运行 <a class="header-anchor" href="#_2、open-webui-最受欢迎的-ai-界面-离线运行" aria-label="Permalink to &quot;2、Open WebUI - 最受欢迎的 AI 界面，离线运行&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-315.png" alt="img" loading="lazy"></p><p><a href="https://github.com/open-webui/open-webui/" target="_blank" rel="noreferrer">Open WebUI </a>是一款非常棒的用户友好型自托管聊天用户界面，旨在完全离线运行。</p><p>你必须安装它才能正确离线使用它：</p><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-316.png" alt="img" loading="lazy"></p><p>可以使用 pip 快速安装它。查看<a href="https://github.com/open-webui/open-webui?tab=readme-ov-file#how-to-install-" target="_blank" rel="noreferrer">完整的安装指南</a>。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># install Open WebUI</span></span>
<span class="line"><span></span></span>
<span class="line"><span>pip install open-webui</span></span>
<span class="line"><span></span></span>
<span class="line"><span># run Open WebUI</span></span>
<span class="line"><span></span></span>
<span class="line"><span>open-webui serve</span></span></code></pre></div><p>让我们看看一些很棒的功能。</p><ul><li>可以自定义 OpenAI API URL 以链接到 LMStudio、GroqCloud、Mistral、OpenRouter 等。</li><li>可以使用我们的国际化 (i18n) 支持以你喜欢的语言使用它。</li><li>有一个免提语音和视频通话功能选项，可以提供更多的灵活性。</li><li>官方网站上有关于社区的一系列模型、提示、工具和功能的清晰信息。</li><li>可以将文档直接加载到聊天中，也可以将文件添加到文档库中，并在查询前使用 # 命令访问它们。</li><li>可以使用 SearXNG、Google PSE、Brave Search、serpstack、serper、Serply、DuckDuckGo、TavilySearch 和 SearchApi 等提供商执行网络搜索，将结果直接注入你的聊天体验中。</li></ul><p>你可以在<a href="https://docs.openwebui.com/" target="_blank" rel="noreferrer">这里</a>阅读文档，其中包括入门指南、常见问题解答（推荐阅读）和教程。</p><p>它是使用 Svelte、Python 和 TypeScript 构建的，在<a href="https://github.com/open-webui/open-webui/" target="_blank" rel="noreferrer"> GitHub </a>上有 41.6k 颗星，这充分说明了它的受欢迎程度。</p><h2 id="_3、librechat-chatgpt-克隆但好-100-倍" tabindex="-1">3、LibreChat - ChatGPT 克隆但好 100 倍 <a class="header-anchor" href="#_3、librechat-chatgpt-克隆但好-100-倍" aria-label="Permalink to &quot;3、LibreChat - ChatGPT 克隆但好 100 倍&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-317.png" alt="img" loading="lazy"></p><p><a href="https://github.com/danny-avila/LibreChat/" target="_blank" rel="noreferrer">LibreChat </a>使用 OpenAI 的 ChatGPT 汇集了助手 AI 的未来。它还可以整合集成并改进原始客户端功能，例如对话和消息搜索、提示模板和插件。</p><p>使用 LibreChat，你不再需要选择 ChatGPT Plus，而是可以使用免费或按通话付费的 API。</p><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-318.png" alt="img" loading="lazy"></p><p>你可以在 <a href="https://librechat-librechat.hf.space/c/new/" target="_blank" rel="noreferrer">librechat-librechat.hf.space </a>查看演示。</p><p>让我们看看一些很棒的功能：</p><ul><li>可以添加多对话。并使用语音转文本 (STT) 和文本转语音 (TTS)。</li><li>模型集合非常疯狂，例如 Anthropic (Claude)、AWS Bedrock、OpenAI、Azure OpenAI、BingAI、ChatGPT、Google Vertex AI、插件、助手 API（包括 Azure 助手）。这为你提供了完整的功能和多种选择。</li><li>可以使用自定义端点、OpenAI、Azure、Anthropic 和 Google 附加文件和聊天。</li><li>可以使用对话分支编辑、重新提交和继续消息。它提供 20 多种语言版本。</li><li>可以创建、保存和共享自定义预设。此外，你甚至可以将聊天导出为屏幕截图、Markdown、文本和 JSON。</li></ul><p>不可能在这里详细介绍所有扩展和插件，因此请自行探索。你可以在<a href="https://www.librechat.ai/docs/" target="_blank" rel="noreferrer">文档</a>中详细查看所有这些功能，其中包括用户指南、插件、详细安装指南等。</p><p>LibreChat 在社区中非常有名，阅读本文后你就可以理解为什么。他们在<a href="https://github.com/danny-avila/LibreChat/" target="_blank" rel="noreferrer"> GitHub </a>上有 18k 颗星，并且使用 TypeScript 构建。</p><h2 id="_4、chatbot-ui-最受欢迎的聊天机器人模板" tabindex="-1">4、Chatbot UI - 最受欢迎的聊天机器人模板 <a class="header-anchor" href="#_4、chatbot-ui-最受欢迎的聊天机器人模板" aria-label="Permalink to &quot;4、Chatbot UI - 最受欢迎的聊天机器人模板&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-319.png" alt="img" loading="lazy"></p><p>与 Vercel 聊天机器人相比，<a href="https://github.com/mckaywrigley/chatbot-ui/" target="_blank" rel="noreferrer">Chatbot UI</a>是一个更受欢迎的聊天机器人，并且它具有 Vercel 中引用的语法突出显示功能。</p><p>我很久以前就从事过一个项目，据我所知，它在组件中提到过。</p><p>它们没有很多花哨的功能，但支持任何人可能需要的大多数东西。</p><p>你可以在云中运行自己的 Chatbot UI 实例，甚至可以在本地运行。也可以在 <a href="https://www.chatbotui.com/" target="_blank" rel="noreferrer">chatbotui.com</a> 查看实时演示。</p><p>需要注意的一点是，即使默认情况下，你也必须使用自己的 OpenAI API 密钥。</p><p>他们在 <a href="https://github.com/mckaywrigley/chatbot-ui/" target="_blank" rel="noreferrer">GitHub </a>上有 28.5k 颗星，并且是使用 TypeScript 构建的。</p><h2 id="_5、vercel-chatbot-vercel-的聊天机器人模板" tabindex="-1">5、Vercel Chatbot - Vercel 的聊天机器人模板 <a class="header-anchor" href="#_5、vercel-chatbot-vercel-的聊天机器人模板" aria-label="Permalink to &quot;5、Vercel Chatbot - Vercel 的聊天机器人模板&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-320.png" alt="img" loading="lazy"></p><p><a href="https://github.com/vercel/ai-chatbot/" target="_blank" rel="noreferrer">Vercel Chatbot</a>是由 Vercel 创建的，它使用基于 Nextjs 的 Vercel AI SDK。</p><p>这更像是一个聊天机器人模板，而不是使用最新模型的完整界面。</p><p>此模板默认附带 OpenAI gpt-3.5-turbo。 但多亏了 Vercel AI SDK，你只需几行代码就可以将 LLM 提供商切换到 Anthropic、Cohere、Hugging Face 或使用 LangChain。</p><p>如果你愿意，也可以<a href="https://github.com/vercel/ai-chatbot?tab=readme-ov-file#running-locally" target="_blank" rel="noreferrer">在本地安装</a>和使用它。</p><p>他们在<a href="https://github.com/vercel/ai-chatbot/" target="_blank" rel="noreferrer"> GitHub </a>上有 6.3k 颗星，功能方面并不是很好。</p><h2 id="_6、deep-chat-可注入你网站的-ai-聊天组件" tabindex="-1">6、Deep Chat - 可注入你网站的 AI 聊天组件 <a class="header-anchor" href="#_6、deep-chat-可注入你网站的-ai-聊天组件" aria-label="Permalink to &quot;6、Deep Chat - 可注入你网站的 AI 聊天组件&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-322.png" alt="img" loading="lazy"></p><p><a href="https://github.com/OvidijusParsiunas/deep-chat/" target="_blank" rel="noreferrer">Deep Chat</a> 是一个完全可定制的 AI 聊天组件，可以毫不费力地用于你的网站。</p><p>你可以在<a href="https://deepchat.dev/playground/" target="_blank" rel="noreferrer"> deepchat.dev/playground </a>查看现场演示。</p><p>它还可用于在组件内创建新文件！单击相机按钮拍摄照片或使用麦克风按钮录制音频。</p><p>也可以使用语音转文本。</p><p>如果你使用 React，这就是可以开始使用的方法。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>npm install deep-chat-react</span></span>
<span class="line"><span></span></span>
<span class="line"><span>// add this to the markup</span></span>
<span class="line"><span></span></span>
<span class="line"><span>&lt;deep-chat&gt;&lt;/deep-chat&gt;</span></span></code></pre></div><p>之后，可以根据你的要求简单地连接。</p><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-323.png" alt="img" loading="lazy"></p><p>确切的语法可能因你的框架而异。他们在<a href="https://deepchat.dev/examples/frameworks/" target="_blank" rel="noreferrer">示例</a>中清楚地记录了它。</p><p>你可以阅读<a href="https://deepchat.dev/docs/introduction/" target="_blank" rel="noreferrer">包含安装指南的文档</a>。</p><p>他们在 <a href="https://github.com/OvidijusParsiunas/deep-chat/" target="_blank" rel="noreferrer">GitHub</a> 上有 1.4k 颗星，并且使用 TypeScript 构建。</p><h2 id="_7、huggingface-chat-使用开源模型的聊天应用" tabindex="-1">7、Huggingface Chat - 使用开源模型的聊天应用 <a class="header-anchor" href="#_7、huggingface-chat-使用开源模型的聊天应用" aria-label="Permalink to &quot;7、Huggingface Chat - 使用开源模型的聊天应用&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-324.png" alt="img" loading="lazy"></p><p><a href="https://github.com/huggingface/chat-ui/" target="_blank" rel="noreferrer">Huggingface Chat</a>是使用开源模型（例如 OpenAssistant 或 Llama）的聊天界面。这是一款 SvelteKit 应用，它为 HuggingChat 应用提供支持。</p><p>这是最受欢迎的 AI 聊天界面之一，原因显而易见。</p><p>让我们看看一些很棒的功能。</p><ul><li>他们提供了 182 个有用的社区工具，你可以根据趋势和流行程度进行筛选。</li><li>他们提供了许多助手，你可以根据模型进行选择。建议阅读<a href="https://huggingface.co/spaces/huggingchat/chat-ui/discussions/357/" target="_blank" rel="noreferrer">官方讨论</a>。</li><li>你可以选择好的模型并描述系统提示，这是自定义体验的另一种方式。</li></ul><p>你可以阅读<a href="https://huggingface.co/docs/chat-ui/index/" target="_blank" rel="noreferrer">文档</a>，在其中可以找到有关架构和快速入门指南的更多信息。</p><p>它们在 <a href="https://github.com/huggingface/chat-ui/" target="_blank" rel="noreferrer">GitHub </a>上有 7.3k 颗星，并且基于 TypeScript 构建。</p><h2 id="_8、speechgpt-使用-gpt-聊天-重点是语音" tabindex="-1">8、SpeechGPT - 使用 GPT 聊天，重点是语音 <a class="header-anchor" href="#_8、speechgpt-使用-gpt-聊天-重点是语音" aria-label="Permalink to &quot;8、SpeechGPT - 使用 GPT 聊天，重点是语音&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-325.png" alt="img" loading="lazy"></p><p><a href="https://github.com/hahahumble/speechgpt/" target="_blank" rel="noreferrer">SpeechGPT </a>是一个 Web 应用程序，可让你与 ChatGPT 交谈。</p><p>可以利用此应用程序来提高你的语言能力，或者只是享受与 ChatGPT 聊天的乐趣。</p><p>大多数人会说它有什么独特之处，但实际上它确实很独特。</p><p>让我们来介绍一些很棒的功能：</p><ul><li>所有数据都存储在本地，从而可以增强隐私。</li><li>根据文档，它支持 100 多种语言，但我只能在现场演示中看到对三种语言的支持。</li><li>包括内置语音识别和与 Azure 语音服务的集成。</li><li>包括内置语音合成，以及与 Amazon Polly 和 Azure 语音服务的集成。</li></ul><p>按照文档中的<a href="https://github.com/hahahumble/speechgpt?tab=readme-ov-file#-tutorial" target="_blank" rel="noreferrer">教程</a>了解如何使用它。</p><p>你可以在<a href="https://speechgpt.app/" target="_blank" rel="noreferrer">speechgpt.app</a>上看到现场演示。这是一个完美的例子，说明几个额外的功能如何将你的应用提升到一个新的水平！</p><p>SpeechGPT在<a href="https://github.com/hahahumble/speechgpt/" target="_blank" rel="noreferrer">GitHub</a>上有2.7k颗星，并且是v0.5.1版本。</p><h2 id="_9、nextchat-跨平台的chatgpt和gemini-ui" tabindex="-1">9、NextChat - 跨平台的ChatGPT和Gemini UI <a class="header-anchor" href="#_9、nextchat-跨平台的chatgpt和gemini-ui" aria-label="Permalink to &quot;9、NextChat - 跨平台的ChatGPT和Gemini UI&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-326.png" alt="img" loading="lazy"></p><p>只需一键即可获得精心设计的跨平台<a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/" target="_blank" rel="noreferrer">ChatGPT Web UI</a>，支持GPT3、GPT4和Gemini Pro（Web / PWA / Linux / Win / MacOS）。</p><p>一些很棒的功能是：</p><ul><li>隐私第一，所有数据都本地存储在浏览器中。</li><li>自动压缩聊天记录以支持长时间对话，同时保存你的令牌。</li><li>Linux / Windows / MacOS上的紧凑型客户端（~5MB）。</li><li>只需在 1 分钟内单击 Vercel 即可免费部署。</li><li>与自行部署的 LLM 完全兼容。</li><li>Markdown 支持：LaTex、mermaid、代码高亮等。</li></ul><p>你可以查看 NextChat 的现场演示和文档，其中包括所有环境变量（主要是 API 密钥）的列表。</p><p>在本地操作并不难，他们还提供了一个 GitHub 操作工作流，每小时都会自动更新。</p><p>NextChat 在<a href="https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/" target="_blank" rel="noreferrer"> GitHub </a>上有 75.5k+ 颗星，并且是 v2.2 版本。</p><h2 id="_10、gpt4all-在任何设备上运行本地-llm" tabindex="-1">10、GPT4All - 在任何设备上运行本地 LLM <a class="header-anchor" href="#_10、gpt4all-在任何设备上运行本地-llm" aria-label="Permalink to &quot;10、GPT4All - 在任何设备上运行本地 LLM&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-327.png" alt="img" loading="lazy"></p><p><a href="https://github.com/nomic-ai/gpt4all/" target="_blank" rel="noreferrer">GPT4All</a> 私下运行大型语言模型 (LLM)。你不需要任何 API 调用或 GPU。</p><p>只需从官方网站下载应用程序并开始使用。它适用于 Windows、MacOS 和 Ubuntu。</p><p>让我们快速浏览一些很棒的统计数据。</p><ul><li>可以将 GPT4All LLM 与敏感的本地数据一起使用，而无需离开你的设备。</li><li>GPT4All 允许你在 CPU 和 GPU 上运行 LLM。它完全支持 Mac M 系列芯片、AMD 和 NVIDIA GPU。</li><li>可以使用本地文件聊天。</li><li>根据官方网站，有超过 1000 种可用的开源语言模型。这是一个疯狂的数字。</li><li>可以使用自己的系统提示、温度、上下文长度、批处理大小等自定义聊天机器人体验</li></ul><p>你可以探索模型，它会显示它是否与你的系统兼容。你可以在那里插入 API 密钥并进行过滤。</p><p>你可以阅读<a href="https://docs.gpt4all.io/" target="_blank" rel="noreferrer">文档</a>，包括快速入门指南和有关所有模型的信息。如果您想将其合并到您的代码库中，他们还提供 Python SDK。</p><p>我还建议阅读有关 GPT4All 3.0 桌面应用程序发布的<a href="https://www.nomic.ai/blog/posts/one-year-of-gpt4all" target="_blank" rel="noreferrer">官方博客</a>。</p><p>他们在<a href="https://github.com/nomic-ai/gpt4all/" target="_blank" rel="noreferrer"> GitHub</a> 上有 69.8k 颗星，并且使用 C++ 构建。</p><h2 id="_11、jan-chatgpt-的开源替代品" tabindex="-1">11、Jan - ChatGPT 的开源替代品 <a class="header-anchor" href="#_11、jan-chatgpt-的开源替代品" aria-label="Permalink to &quot;11、Jan - ChatGPT 的开源替代品&quot;">​</a></h2><p><img src="http://www.hubwiz.com/blog/content/images/2025/02/image-328.png" alt="img" loading="lazy"></p><p><a href="https://jan.ai/" target="_blank" rel="noreferrer">Jan </a>是 ChatGPT 的开源替代品，可 100% 离线运行在你的计算机上。多引擎支持 (llama.cpp、TensorRT-LLM)</p><p>你必须根据你的操作系统下载它。最好的部分是 Jan 没有付费版本。</p><p><a href="https://github.com/janhq/jan?tab=readme-ov-file#demo" target="_blank" rel="noreferrer">这里</a>是 Jan 的快速演示。</p><p>Jan有很多功能，如个性化 AI 助手和扩展，你可以自己探索。</p><p>你可以阅读<a href="https://jan.ai/docs/" target="_blank" rel="noreferrer">文档</a>，其中包括快速入门指南和所用模型的信息。你可以连接你的文件，但它仍然是一个实验性功能。</p><p>你甚至可以将 Jan 与 Continue 代码编辑器集成，这会让事情变得非常有趣。阅读文档中的指南。</p><p>Jan的总下载量为 170 万+，因此他们非常可信，因为他们有一个庞大的社区。</p><p>Jan 在<a href="https://github.com/janhq/jan/" target="_blank" rel="noreferrer"> GitHub</a> 上有 22.6k 颗星，是使用 TypeScript 构建的。</p><h2 id="联系我" tabindex="-1">联系我 <a class="header-anchor" href="#联系我" aria-label="Permalink to &quot;联系我&quot;">​</a></h2><p>最后，推荐大家关注一下开源项目：LangChat，Java生态下的AIGC大模型产品解决方案。</p><ul><li>LangChat产品官网：<a href="https://langchat.cn/" target="_blank" rel="noreferrer">https://langchat.cn/</a></li><li>Github: <a href="https://github.com/TyCoding/langchat" target="_blank" rel="noreferrer">https://github.com/TyCoding/langchat</a></li><li>Gitee: <a href="https://gitee.com/langchat/langchat" target="_blank" rel="noreferrer">https://gitee.com/langchat/langchat</a></li><li>微信：LangchainChat</li></ul><p><img src="http://cdn.tycoding.cn/docs/202502151026673.png" alt="" loading="lazy"></p></div></div></main><footer class="VPDocFooter" data-v-479a6568 data-v-a9f44413><!--[--><!--]--><div class="edit-info" data-v-a9f44413><!----><div class="last-updated" data-v-a9f44413><p class="VPLastUpdated" data-v-a9f44413 data-v-0500d987>Last updated: <time datetime="2025-02-26T01:05:02.000Z" data-v-0500d987></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-a9f44413><span class="visually-hidden" id="doc-footer-aria-label" data-v-a9f44413>Pager</span><div class="pager" data-v-a9f44413><a class="VPLink link pager-link prev" href="/docs/other/top8-on-premise-plans-for-deepseek-r1.html" data-v-a9f44413><!--[--><span class="desc" data-v-a9f44413>Previous page</span><span class="title" data-v-a9f44413>8个DeepSeek-R1私有化部署方案</span><!--]--></a></div><div class="pager" data-v-a9f44413><a class="VPLink link pager-link next" href="/docs/other/vllm-llm-local-inference-library.html" data-v-a9f44413><!--[--><span class="desc" data-v-a9f44413>Next page</span><span class="title" data-v-a9f44413>vLLM 大模型本地推理库</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"docs_deploy_deploy.md\":\"Dg2bS27a\",\"docs_exercise_langchat-deepseek-r1.md\":\"BG1HS0Jq\",\"docs_exercise_oss-minio.md\":\"BKGFqqWT\",\"docs_exercise_rag.md\":\"YedSmvND\",\"docs_other_bank.md\":\"5tiAkFLT\",\"docs_other_chunking-strategies.md\":\"gV_LewAr\",\"docs_other_claude-3-7-sonnet.md\":\"Dj1Hhibl\",\"docs_other_deepseek-r1-architecture-and-training.md\":\"0Z6H9Kbq\",\"docs_other_deepseek-r1-distilled-models.md\":\"4nK05JS_\",\"docs_other_deepseek-r1-reasoning-capabilities-analysis.md\":\"B5CK-D6e\",\"docs_other_deepseek-r1-tuning.md\":\"CdRsqumj\",\"docs_other_distill-deepseek-r1-into-your-model.md\":\"DdEwVv1R\",\"docs_other_guide-getting-started-with-cursor-and-deepseek-r1.md\":\"CrF2GZkG\",\"docs_other_hardware-guide-for-llm-training-and-fine-tuning.md\":\"CyLRPjt8\",\"docs_other_markitdown-a-deep-dive.md\":\"Cs6UPOgy\",\"docs_other_reasoning-modes-vs-other-ai-models.md\":\"BmYH1TUj\",\"docs_other_the-ai-web-search-landscape.md\":\"C4xGfer5\",\"docs_other_top11-ai-chat-ui-for-developers.md\":\"CSnixW_I\",\"docs_other_top8-on-premise-plans-for-deepseek-r1.md\":\"BroA2pse\",\"docs_other_vllm-llm-local-inference-library.md\":\"7uM8sIzs\",\"docs_other_vllm-ollama-comprehensive-comparison.md\":\"D9IVeAkT\",\"docs_other_vllm-vs-ollama.md\":\"BRFYvY27\",\"docs_start_environment.md\":\"DkSgePUm\",\"docs_start_getting-started.md\":\"B8WJQYY8\",\"docs_start_introduce.md\":\"CgbmexuX\",\"docs_start_knowledge.md\":\"Ce41O1tK\",\"docs_start_login.md\":\"DWOURVt-\",\"docs_start_models-proxy.md\":\"6b6woVJN\",\"docs_start_models.md\":\"Ds4X4F2M\",\"docs_start_questions.md\":\"AMWgx7AD\",\"index.md\":\"n9TEBaM7\",\"readme.md\":\"DKy5OORU\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"LangChat Docs\",\"description\":\"LangChat Project Document\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":{\"level\":\"deep\"},\"search\":{\"provider\":\"local\"},\"nav\":[{\"text\":\"LangChat\",\"link\":\"/\"},{\"text\":\"LangChat文档\",\"link\":\"/docs/exercise/langchat-deepseek-r1\",\"activeMatch\":\"/docs\"},{\"text\":\"在线预览\",\"items\":[{\"text\":\"LangChat官网\",\"link\":\"https://langchat.cn/\"},{\"text\":\"LangChat后台预览\",\"link\":\"http://backend.langchat.cn/\"},{\"text\":\"LangChat LLM Ops\",\"link\":\"http://llm.langchat.cn\"},{\"text\":\"LangChat UPMS Ops\",\"link\":\"http://upms.langchat.cn\"}]}],\"sidebar\":{\"/docs\":[{\"text\":\"LangChat实战\",\"items\":[{\"text\":\"DeepSeek-R1实战\",\"link\":\"/docs/exercise/langchat-deepseek-r1\"},{\"text\":\"使用Minio作为OSS\",\"link\":\"/docs/exercise/oss-minio\"},{\"text\":\"LLM-RAG基础概念\",\"link\":\"/docs/exercise/rag\"}]},{\"text\":\"LangChat配置\",\"items\":[{\"text\":\"LangChat介绍\",\"link\":\"/docs/start/introduce\"},{\"text\":\"环境准备\",\"link\":\"/docs/start/environment\"},{\"text\":\"快速开始\",\"link\":\"/docs/start/getting-started\"},{\"text\":\"登录LangChat\",\"link\":\"/docs/start/login\"},{\"text\":\"模型配置\",\"link\":\"/docs/start/models\"},{\"text\":\"模型代理\",\"link\":\"/docs/start/models-proxy\"},{\"text\":\"知识库\",\"link\":\"/docs/start/knowledge\"},{\"text\":\"常见问题\",\"link\":\"/docs/start/questions\"}]},{\"text\":\"LangChat部署\",\"items\":[{\"text\":\"LangChat部署教程\",\"link\":\"/docs/deploy/deploy\"}]},{\"text\":\"推荐阅读\",\"items\":[{\"text\":\"大模型RAG中的分块策略\",\"link\":\"/docs/other/chunking-strategies\"},{\"text\":\"Claude 3.7 Sonnet强势来袭\",\"link\":\"/docs/other/claude-3-7-sonnet\"},{\"text\":\"DeepSeek R1架构和训练过程图解\",\"link\":\"/docs/other/deepseek-r1-architecture-and-training\"},{\"text\":\"DeepSeek-R1蒸馏模型\",\"link\":\"/docs/other/deepseek-r1-distilled-models\"},{\"text\":\"DeepSeek-R1的推理能力分析\",\"link\":\"/docs/other/deepseek-r1-reasoning-capabilities-analysis\"},{\"text\":\"DeepSeek-R1微调指南\",\"link\":\"/docs/other/deepseek-r1-tuning\"},{\"text\":\"蒸馏DeepSeek-R1到自己的模型\",\"link\":\"/docs/other/distill-deepseek-r1-into-your-model\"},{\"text\":\"Cursor + DeepSeek R1 使用指南\",\"link\":\"/docs/other/guide-getting-started-with-cursor-and-deepseek-r1\"},{\"text\":\"大模型训练/微调硬件指南\",\"link\":\"/docs/other/hardware-guide-for-llm-training-and-fine-tuning\"},{\"text\":\"MarkItDown深入研究\",\"link\":\"/docs/other/markitdown-a-deep-dive\"},{\"text\":\"推理模型 vs. 其他AI模型\",\"link\":\"/docs/other/reasoning-modes-vs-other-ai-models\"},{\"text\":\"AI搜索引擎生态全景\",\"link\":\"/docs/other/the-ai-web-search-landscape\"},{\"text\":\"8个DeepSeek-R1私有化部署方案\",\"link\":\"/docs/other/top8-on-premise-plans-for-deepseek-r1\"},{\"text\":\"11个开发人员必备AI聊天界面\",\"link\":\"/docs/other/top11-ai-chat-ui-for-developers\"},{\"text\":\"vLLM 大模型本地推理库\",\"link\":\"/docs/other/vllm-llm-local-inference-library\"},{\"text\":\"vLLM/ollama综合对比\",\"link\":\"/docs/other/vllm-ollama-comprehensive-comparison\"},{\"text\":\"VLLM vs. Ollama\",\"link\":\"/docs/other/vllm-vs-ollama\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/TyCoding/langchat\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>