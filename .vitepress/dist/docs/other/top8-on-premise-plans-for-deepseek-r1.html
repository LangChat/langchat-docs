<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>8个DeepSeek-R1私有化部署方案 | LangChat Docs</title>
    <meta name="description" content="LangChat Project Document">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.wFIoVwSX.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.Cjw_v9nb.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.BoyLCJnS.js">
    <link rel="modulepreload" href="/assets/chunks/framework.ByciF0Oj.js">
    <link rel="modulepreload" href="/assets/docs_other_top8-on-premise-plans-for-deepseek-r1.md.BroA2pse.lean.js">
    <link rel="shortcut icon" href="/favicon.png">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-ed470ed6><!--[--><!--]--><!--[--><span tabindex="-1" data-v-f444f753></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-f444f753>Skip to content</a><!--]--><!----><header class="VPNav" data-v-ed470ed6 data-v-f09ebc71><div class="VPNavBar" data-v-f09ebc71 data-v-1044928a><div class="wrapper" data-v-1044928a><div class="container" data-v-1044928a><div class="title" data-v-1044928a><div class="VPNavBarTitle has-sidebar" data-v-1044928a data-v-c494e956><a class="title" href="/" data-v-c494e956><!--[--><!--]--><!----><span data-v-c494e956>LangChat Docs</span><!--[--><!--]--></a></div></div><div class="content" data-v-1044928a><div class="content-body" data-v-1044928a><!--[--><!--]--><div class="VPNavBarSearch search" data-v-1044928a><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-1044928a data-v-51f1f89a><span id="main-nav-aria-label" class="visually-hidden" data-v-51f1f89a> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-51f1f89a data-v-2ebde2b3><!--[--><span data-v-2ebde2b3>LangChat</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/docs/exercise/langchat-deepseek-r1.html" tabindex="0" data-v-51f1f89a data-v-2ebde2b3><!--[--><span data-v-2ebde2b3>LangChat文档</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-51f1f89a data-v-e2cb7df8><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-e2cb7df8><span class="text" data-v-e2cb7df8><!----><span data-v-e2cb7df8>在线预览</span><span class="vpi-chevron-down text-icon" data-v-e2cb7df8></span></span></button><div class="menu" data-v-e2cb7df8><div class="VPMenu" data-v-e2cb7df8 data-v-7750fdeb><div class="items" data-v-7750fdeb><!--[--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="https://langchat.cn/" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat官网</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="http://backend.langchat.cn/" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat后台预览</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="http://llm.langchat.cn" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat LLM Ops</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7750fdeb data-v-9a9070ef><a class="VPLink link vp-external-link-icon" href="http://upms.langchat.cn" target="_blank" rel="noreferrer" data-v-9a9070ef><!--[--><span data-v-9a9070ef>LangChat UPMS Ops</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-1044928a data-v-adf2275d><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-adf2275d data-v-4cc58f0d data-v-f45163c9><span class="check" data-v-f45163c9><span class="icon" data-v-f45163c9><!--[--><span class="vpi-sun sun" data-v-4cc58f0d></span><span class="vpi-moon moon" data-v-4cc58f0d></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-1044928a data-v-17ef9bfb data-v-34ec2aad><!--[--><a class="VPSocialLink no-icon" href="https://github.com/TyCoding/langchat" aria-label="github" target="_blank" rel="noopener" data-v-34ec2aad data-v-6953ab1f><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-1044928a data-v-a84198a3 data-v-e2cb7df8><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-e2cb7df8><span class="vpi-more-horizontal icon" data-v-e2cb7df8></span></button><div class="menu" data-v-e2cb7df8><div class="VPMenu" data-v-e2cb7df8 data-v-7750fdeb><!----><!--[--><!--[--><!----><div class="group" data-v-a84198a3><div class="item appearance" data-v-a84198a3><p class="label" data-v-a84198a3>Appearance</p><div class="appearance-action" data-v-a84198a3><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-a84198a3 data-v-4cc58f0d data-v-f45163c9><span class="check" data-v-f45163c9><span class="icon" data-v-f45163c9><!--[--><span class="vpi-sun sun" data-v-4cc58f0d></span><span class="vpi-moon moon" data-v-4cc58f0d></span><!--]--></span></span></button></div></div></div><div class="group" data-v-a84198a3><div class="item social-links" data-v-a84198a3><div class="VPSocialLinks social-links-list" data-v-a84198a3 data-v-34ec2aad><!--[--><a class="VPSocialLink no-icon" href="https://github.com/TyCoding/langchat" aria-label="github" target="_blank" rel="noopener" data-v-34ec2aad data-v-6953ab1f><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-1044928a data-v-5598f36f><span class="container" data-v-5598f36f><span class="top" data-v-5598f36f></span><span class="middle" data-v-5598f36f></span><span class="bottom" data-v-5598f36f></span></span></button></div></div></div></div><div class="divider" data-v-1044928a><div class="divider-line" data-v-1044928a></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-ed470ed6 data-v-d1ebcfd2><div class="container" data-v-d1ebcfd2><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-d1ebcfd2><span class="vpi-align-left menu-icon" data-v-d1ebcfd2></span><span class="menu-text" data-v-d1ebcfd2>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-d1ebcfd2 data-v-8683af8e><button data-v-8683af8e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-ed470ed6 data-v-b5cecb30><div class="curtain" data-v-b5cecb30></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-b5cecb30><span class="visually-hidden" id="sidebar-aria-label" data-v-b5cecb30> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>LangChat实战</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/exercise/langchat-deepseek-r1.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1实战</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/exercise/oss-minio.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>使用Minio作为OSS</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/exercise/rag.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>LLM-RAG基础概念</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>LangChat配置</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/introduce.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>LangChat介绍</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/environment.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>环境准备</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/getting-started.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>快速开始</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/login.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>登录LangChat</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/models.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>模型配置</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/models-proxy.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>模型代理</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/knowledge.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>知识库</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/start/questions.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>常见问题</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>LangChat部署</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/deploy/deploy.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>LangChat部署教程</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-d47b2d47><section class="VPSidebarItem level-0 has-active" data-v-d47b2d47 data-v-f455531b><div class="item" role="button" tabindex="0" data-v-f455531b><div class="indicator" data-v-f455531b></div><h2 class="text" data-v-f455531b>推荐阅读</h2><!----></div><div class="items" data-v-f455531b><!--[--><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/chunking-strategies.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>大模型RAG中的分块策略</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/claude-3-7-sonnet.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>Claude 3.7 Sonnet强势来袭</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-architecture-and-training.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek R1架构和训练过程图解</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-distilled-models.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1蒸馏模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-reasoning-capabilities-analysis.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1的推理能力分析</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/deepseek-r1-tuning.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>DeepSeek-R1微调指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/distill-deepseek-r1-into-your-model.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>蒸馏DeepSeek-R1到自己的模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/guide-getting-started-with-cursor-and-deepseek-r1.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>Cursor + DeepSeek R1 使用指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/hardware-guide-for-llm-training-and-fine-tuning.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>大模型训练/微调硬件指南</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/markitdown-a-deep-dive.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>MarkItDown深入研究</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/reasoning-modes-vs-other-ai-models.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>推理模型 vs. 其他AI模型</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/the-ai-web-search-landscape.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>AI搜索引擎生态全景</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/top8-on-premise-plans-for-deepseek-r1.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>8个DeepSeek-R1私有化部署方案</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/top11-ai-chat-ui-for-developers.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>11个开发人员必备AI聊天界面</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/vllm-llm-local-inference-library.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>vLLM 大模型本地推理库</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/vllm-ollama-comprehensive-comparison.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>vLLM/ollama综合对比</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-f455531b data-v-f455531b><div class="item" data-v-f455531b><div class="indicator" data-v-f455531b></div><a class="VPLink link link" href="/docs/other/vllm-vs-ollama.html" data-v-f455531b><!--[--><p class="text" data-v-f455531b>VLLM vs. Ollama</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-ed470ed6 data-v-ee4370c0><div class="VPDoc has-sidebar has-aside" data-v-ee4370c0 data-v-479a6568><!--[--><!--]--><div class="container" data-v-479a6568><div class="aside" data-v-479a6568><div class="aside-curtain" data-v-479a6568></div><div class="aside-container" data-v-479a6568><div class="aside-content" data-v-479a6568><div class="VPDocAside" data-v-479a6568 data-v-312359a6><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-312359a6 data-v-f9862b92><div class="content" data-v-f9862b92><div class="outline-marker" data-v-f9862b92></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-f9862b92>On this page</div><ul class="VPDocOutlineItem root" data-v-f9862b92 data-v-316b2cab><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-312359a6></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-479a6568><div class="content-container" data-v-479a6568><!--[--><!--]--><main class="main" data-v-479a6568><div style="position:relative;" class="vp-doc _docs_other_top8-on-premise-plans-for-deepseek-r1" data-v-479a6568><div><h1 id="_8个deepseek-r1私有化部署方案" tabindex="-1">8个DeepSeek-R1私有化部署方案 <a class="header-anchor" href="#_8个deepseek-r1私有化部署方案" aria-label="Permalink to &quot;8个DeepSeek-R1私有化部署方案&quot;">​</a></h1><blockquote><p>本文了解如何在本地和没有互联网的情况下运行DeepSeek R1推理模型，或者通过可信赖的托管服务来运行它。</p></blockquote><h3 id="关于langchat" tabindex="-1">关于LangChat <a class="header-anchor" href="#关于langchat" aria-label="Permalink to &quot;关于LangChat&quot;">​</a></h3><p><strong>LangChat</strong> 是Java生态下企业级AIGC项目解决方案，集成RBAC和AIGC大模型能力，帮助企业快速定制AI知识库、企业AI机器人。</p><p><strong>支持的AI大模型：</strong> Gitee AI / 阿里通义 / 百度千帆 / DeepSeek / 抖音豆包 / 智谱清言 / 零一万物 / 讯飞星火 / OpenAI / Gemini / Ollama / Azure / Claude 等大模型。</p><ul><li>官网地址：<a href="http://langchat.cn/" target="_blank" rel="noreferrer">http://langchat.cn/</a></li></ul><p><strong>开源地址：</strong></p><ul><li>Gitee：<a href="https://gitee.com/langchat/langchat" target="_blank" rel="noreferrer">https://gitee.com/langchat/langchat</a></li><li>Github：<a href="https://github.com/tycoding/langchat" target="_blank" rel="noreferrer">https://github.com/tycoding/langchat</a></li></ul><p><img src="http://cdn.tycoding.cn/docs/202502151026673.png" alt="iShot_2025-02-12_12.18.53" loading="lazy"></p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*Dm7EMdphvaX7BdXnUpbGCw.png" alt="img" loading="lazy"></p><p>运行DeepSeek R1 fffline并托管</p><p>许多人（尤其是开发人员）想使用新的<a href="https://api-docs.deepseek.com/news/news250120" target="_blank" rel="noreferrer">DeepSeek R1</a>思维模型，但担心将其数据发送到<a href="https://www.deepseek.com/" target="_blank" rel="noreferrer">DeepSeek</a> 。阅读本文，以了解如何在本地和不使用Internet或使用受信任的托管服务的情况下使用和运行DeepSeek R1推理模型。您将模型脱机运行，因此您的私人数据与您一起停留，并且不会将计算机留给任何LLM托管提供商（DeepSeek）。同样，借助值得信赖的托管服务，您的数据将转到第三方托管提供商而不是DeepSeek。</p><p>使用LMSTUDIO，OLLAMA和JAN在本地/离线运行DeepSeek R1或通过LLM服务平台，例如Groq，Fireworks AI以及AI共同有助于消除数据共享和隐私问题。</p><h1 id="什么是deepseek-r1" tabindex="-1">什么是DeepSeek R1？ <a class="header-anchor" href="#什么是deepseek-r1" aria-label="Permalink to &quot;什么是DeepSeek R1？&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*OJvhhzHtsFVTkZCu" alt="img" loading="lazy"></p><p>DeepSeek聊天UI</p><p>OpenAI O1和最新模型（例如OpenAI O3和DeepSeek R1）解决了数学，编码，科学和其他领域的复杂问题。这些模型可以考虑从用户查询的输入提示，并在生成最终解决方案之前仔细研究推理步骤或思想链（COT）。在撰写本文时，以上三种语言模型是具有思维能力的模型。 DeepSeek R1模型由基本R1模型和六个蒸馏版组成。蒸馏型从较小的版本到较大的版本，这些版本用Qwen和Llama进行了微调。</p><h1 id="人们为什么要使用r1但存在隐私问题" tabindex="-1">人们为什么要使用R1但存在隐私问题？ <a class="header-anchor" href="#人们为什么要使用r1但存在隐私问题" aria-label="Permalink to &quot;人们为什么要使用R1但存在隐私问题？&quot;">​</a></h1><p>R1模型无疑是世界上最好的推理模型之一。它的功能引起了开发人员社区对<a href="https://x.com/MatthewBerman/status/1884044269201330569" target="_blank" rel="noreferrer">X</a> ， <a href="https://www.reddit.com/r/GetNoted/comments/1ichm8v/openai_employee_gets_noted_regarding_deepseek/" target="_blank" rel="noreferrer">Reddit</a> ， <a href="https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_dont-fall-for-false-deepseek-r1-news-deepseek-activity-7289723903797600256-ox0r?utm_source=share&amp;utm_medium=member_desktop" target="_blank" rel="noreferrer">LinkedIn</a>和其他社交媒体平台的关注和关注。但是，使用DeepSeek提供的语言模型有一些错误的信息和错误的方法。例如，有些人认为DeepSeek是一个附带项目，而不是公司。其他人认为DeepSeek可能会将用户的数据用于其他目的，而不是其隐私政策中所述的内容。像OpenAI一样， <a href="https://chat.deepseek.com/" target="_blank" rel="noreferrer">DeepSeek聊天</a>的托管版本可能会收集用户的数据，并将其用于培训和改进其模型。话虽如此，这并不意味着您不应该相信使用托管的DeepSeek聊天。它与Chatgpt类似，是使用DeepSeek R1模型测试和生成响应的绝佳工具。有些人和公司不希望DeepSeek由于隐私问题而收集数据。此外，DeepSeek总部位于中国，有几个人担心与中国的一家公司共享其私人信息。</p><p>一个人如何在不与DeepSeek共享信息的情况下下载，安装和运行DeepSeek R1的思维模型家族？继续阅读以探索您和您的团队如何在没有互联网的情况下在本地运行DeepSeek R1模型，或者使用欧盟和美国基于美国的托管服务。</p><h1 id="为什么要deepseek-r1" tabindex="-1">为什么要DeepSeek R1？ <a class="header-anchor" href="#为什么要deepseek-r1" aria-label="Permalink to &quot;为什么要DeepSeek R1？&quot;">​</a></h1><p>R1模型背后的公司<a href="https://www.deepseek.com/" target="_blank" rel="noreferrer">DeepSeek</a>最近进入了主流大语言模型（LLM ）提供商，加入<a href="https://openai.com/" target="_blank" rel="noreferrer">Openai</a> ， <a href="https://ai.google.dev/" target="_blank" rel="noreferrer">Google</a> ， <a href="https://www.anthropic.com/" target="_blank" rel="noreferrer">Anthropic</a> ， <a href="https://ai.meta.com/meta-ai/" target="_blank" rel="noreferrer">Meta AI</a> ， <a href="https://groq.com/" target="_blank" rel="noreferrer">Groqinc</a> ， <a href="https://mistral.ai/" target="_blank" rel="noreferrer">Mistral</a>等主要参与者。 DeepSeek R1型号是开源的，成本低于OpenAI O1型号。成为开源为机器学习和开发人员社区提供了长期利益。人们可以为不同用例复制R1模型的版本。尽管成本较低，但它仍与OpenAI O1型号<a href="https://api-docs.deepseek.com/news/news250120" target="_blank" rel="noreferrer">相当</a>。它令人难以置信的推理功能使其成为OpenAI O1型号的绝佳选择。凭借其有趣的推理能力和低成本，许多人（包括开发人员）想使用它来为其AI应用程序供电，但担心将其数据发送到DeepSeek。的确，将DeepSeek R1模型与<a href="https://chat.deepseek.com/" target="_blank" rel="noreferrer">DeepSeek聊天</a>这样的平台使用，您的数据将由DeepSeek收集。但是，您可以在计算机上完全离线运行DeepSeek R1模型，也可以使用托管服务来运行该模型来构建您的AI应用程序。</p><p>像其他大型语言模型（LLMs ），您可以使用<a href="https://getstream.io/blog/best-local-llm-tools/" target="_blank" rel="noreferrer">本地</a>运行并测试原始的DeepSeek R1型号和机器上的DeepSeek R1家族<a href="https://getstream.io/blog/best-local-llm-tools/" target="_blank" rel="noreferrer">LLM托管工具</a>。使用R1型号的一个好处是，它们可以在诸如Groq，foring.ai等托管平台上使用。通过这些平台使用这些模型是通过DeepSeek聊天和API直接使用它们的理想选择。微软最近制作了R1型号，并在其<a href="https://azure.microsoft.com/en-us/blog/deepseek-r1-is-now-available-on-azure-ai-foundry-and-github/" target="_blank" rel="noreferrer">Azure AI Foundry</a>和Github上提供了蒸馏版。</p><h1 id="什么是当地的第一llm工具" tabindex="-1">什么是当地的第一LLM工具？ <a class="header-anchor" href="#什么是当地的第一llm工具" aria-label="Permalink to &quot;什么是当地的第一LLM工具？&quot;">​</a></h1><p>使用时LLMs像<a href="https://chatgpt.com/" target="_blank" rel="noreferrer">Chatgpt</a>或<a href="https://claude.ai/" target="_blank" rel="noreferrer">Claude</a>一样，您也使用OpenAI和Anthropic托管的模型，因此这些提供商可能会收集您的提示和数据来培训和增强其模型的功能。如果您担心将数据发送到这些LLM提供者，您可以使用本地优先LLM工具以离线运行您的首选模型。当地第一LLM工具是一种工具，可让您在不使用网络的情况下聊天和测试模型。使用Lmstudio，Ollama和Jan等工具，您可以与您喜欢的任何型号进行聊天，例如DeepSeek R1型号100％离线。了解有关本地第一的更多信息LLM我们最近的<a href="https://getstream.io/blog/best-local-llm-tools/" target="_blank" rel="noreferrer">文章</a>和<a href="https://youtu.be/pyFRIlk4se0?si=Y2DjgHLH2YZ4OF1R" target="_blank" rel="noreferrer">YouTube教程</a>之一中的工具。</p><h1 id="必备当地人llmdeepseek-r1的工具" tabindex="-1">必备当地人LLMDeepSeek R1的工具 <a class="header-anchor" href="#必备当地人llmdeepseek-r1的工具" aria-label="Permalink to &quot;必备当地人LLMDeepSeek R1的工具&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*wEePc6qX6dPOTSHt" alt="img" loading="lazy"></p><p>与Lmstudio，Jan和Ollama在本地运行DeepSeek R1</p><p>自从DeepSeek R1模型发布以来，本地数量越来越多LLM下载和使用模型的平台而无需连接到Internet。以下是在撰写本文时可以使用R1脱机的三个最佳应用程序。我们将偶尔更新文章作为本地数量LLM工具支持R1增加。</p><h1 id="lmstudio" tabindex="-1">LMStudio <a class="header-anchor" href="#lmstudio" aria-label="Permalink to &quot;LMStudio&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*IvhmppMlz3f48knAdIqoAg.gif" alt="img" loading="lazy"></p><p>使用LMSTUDIO在本地运行DeepSeek R1</p><p>LMstudio提供了可以离线运行的DeepSeek R1的蒸馏版。首先，<a href="https://lmstudio.ai/" target="_blank" rel="noreferrer">下载</a>lmstudio，启动它，然后单击左面板上的**“发现”<strong>选项卡以下载，安装和运行任何蒸馏版R1。在<a href="https://youtube.com/shorts/51aYf_39sBU?si=Axkf1r1H_0S0SxFm" target="_blank" rel="noreferrer">YouTube</a>上</strong>使用LMSTUDIO在本地观看Run Run Run DeepSeek R1，**以便逐步快速指南。</p><h1 id="奥拉马" tabindex="-1">奥拉马 <a class="header-anchor" href="#奥拉马" aria-label="Permalink to &quot;奥拉马&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*2CoGo0NZVvT7u0kl" alt="img" loading="lazy"></p><p>下载Ollama</p><p>使用Ollama，您可以在没有网络的情况下使用单个命令运行DeepSeek R1型号100％。首先，安装<a href="https://ollama.com/" target="_blank" rel="noreferrer">Ollama</a> ，然后运行以下命令来拉动并运行DeepSeek R1模型：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>ollama run deepseek-r1</span></span></code></pre></div><p>您还可以拉动并运行DeepSeek R1型号的以下蒸馏Qwen和Llama版本。</p><p><strong>QWEN蒸馏DeepSeekr1型号</strong></p><ul><li><strong>DeepSeek-R1-Distill-Qwen-1.5b</strong> ： <code>ollama run deepseek-r1:1.5b</code></li><li><strong>DeepSeek-R1-Distill-Qwen-7b</strong> ： <code>ollama run deepseek-r1:7b</code></li><li><strong>DeepSeek-R1-Distill-Qwen-14b</strong> ： <code>ollama run deepseek-r1:14b</code></li><li><strong>DeepSeek-R1-Distill-Qwen-32b</strong> ： <code>ollama run deepseek-r1:32b</code></li></ul><p><strong>美洲驼蒸馏DeepSeekr1模型</strong></p><ul><li><strong>DeepSeek-R1-Distill-Lalama-8B</strong> ： <code>ollama run deepseek-r1:8b</code></li><li><strong>DeepSeek-R1-Distill-Lalama-70b</strong> ： <code>ollama run deepseek-r1:70b</code></li></ul><p>下面的预览展示了如何与Ollama一起运行<strong>DeepSeek-R1-Distill-Lalama-8b</strong> 。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*n6JPQJdCy-bdpgUXUb9Nuw.gif" alt="img" loading="lazy"></p><p>Ollama运行DeepSeek-R1</p><p>观看<strong>Run DeepSeek R1 + Ollama本地LLM</strong>在<a href="https://youtube.com/shorts/qd4Rm7kyksM?si=sDfvA3L52xpHC8TI" target="_blank" rel="noreferrer">YouTube</a>上的<strong>工具</strong>进行快速演练。</p><h1 id="jan-与deepseek-r1离线聊天" tabindex="-1">Jan：与DeepSeek R1离线聊天 <a class="header-anchor" href="#jan-与deepseek-r1离线聊天" aria-label="Permalink to &quot;Jan：与DeepSeek R1离线聊天&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*18XKjTNibGodIawx" alt="img" loading="lazy"></p><p>与Jan下载DeepSeek R1</p><p>Jan将自己描述为一种开源Chatgpt替代方案。这是当地的第一LLM运行DeepSeek R1型号100％离线的工具。使用JAN运行DeepSeek R1仅需要下图中所示的三个步骤。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*IXnHl-tuHbJ1bf44" alt="img" loading="lazy"></p><p>与Jan一起运行DeepSeek R1的步骤</p><p>下载<a href="https://jan.ai/" target="_blank" rel="noreferrer">Jan</a> ，然后前往左图上的<strong>Hub</strong>选项卡，以搜索并下载从<a href="https://huggingface.co/" target="_blank" rel="noreferrer">拥抱面</a>中的任何蒸馏R1 GGUF型号。</p><p><strong>DeepSeek R1 Qwen蒸馏型</strong></p><ul><li>1.5b： <a href="https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-1.5B-GGUF" target="_blank" rel="noreferrer">https</a> ：<a href="//huggingface.co/bartowski/deepseek-r1-distill-qwen-1.5b-gguf" target="_blank" rel="noreferrer">//huggingface.co/bartowski/deepseek-r1-distill-qwen-1.5b-gguf</a></li><li>7b： <a href="https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF" target="_blank" rel="noreferrer">https</a> ：<a href="//hugingface.co/bartowski/deepseek-r1-distill-qwen-7b-gguf" target="_blank" rel="noreferrer">//hugingface.co/bartowski/deepseek-r1-distill-qwen-7b-gguf</a></li><li>14b： <a href="https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF" target="_blank" rel="noreferrer">https</a> ：<a href="//huggingface.co/bartowski/deepseek-r1-distill-qwen-14b-gguf" target="_blank" rel="noreferrer">//huggingface.co/bartowski/deepseek-r1-distill-qwen-14b-gguf</a></li><li>32B： <a href="https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF" target="_blank" rel="noreferrer">https</a> ：<a href="//hugingface.co/bartowski/deepseek-r1-distill-qwen-32b-gguf" target="_blank" rel="noreferrer">//hugingface.co/bartowski/deepseek-r1-distill-qwen-32b-gguf</a></li></ul><p><strong>DeepSeek R1美洲驼蒸馏模型</strong></p><ul><li>8b： <a href="https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF" target="_blank" rel="noreferrer">https</a> ：<a href="//huggingface.co/unsloth/deepseek-r1-distill-llama-8b-gguf" target="_blank" rel="noreferrer">//huggingface.co/unsloth/deepseek-r1-distill-llama-8b-gguf</a></li><li>70B： <a href="https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF" target="_blank" rel="noreferrer">https</a> ：<a href="//hugingface.co/unsloth/deepseek-r1-distill-lma-70b-gguf" target="_blank" rel="noreferrer">//hugingface.co/unsloth/deepseek-r1-distill-lma-70b-gguf</a></li></ul><p>一旦您下载了带有JAN的任何蒸馏R1型号，就可以按照以下预览进行运行。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*qauRmzn7xjPBcH0oejFLAg.gif" alt="img" loading="lazy"></p><p>与Jan一起运行DeepSeek R1</p><h1 id="其他替代方案-使用企业准备就绪llm托管r1托管" tabindex="-1">其他替代方案：使用企业准备就绪LLM托管R1托管 <a class="header-anchor" href="#其他替代方案-使用企业准备就绪llm托管r1托管" aria-label="Permalink to &quot;其他替代方案：使用企业准备就绪LLM托管R1托管&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*9r4fRCBgN-F2J6MEg4NyLg.png" alt="img" loading="lazy"></p><p>DeepSeek R1托管选项</p><p>尽管最近发布了DeepSeek R1模型，但有些值得信赖LLM托管平台支持它。如果您不想使用上面概述的离线方法，则可以从以下任何提供商访问模型。可能有几个LLM在此处陈述的托管平台中缺少平台。但是，以下是领先的平台，您可以在其中访问DeepSeek R1型号及其蒸馏器。</p><h1 id="格罗克" tabindex="-1">格罗克 <a class="header-anchor" href="#格罗克" aria-label="Permalink to &quot;格罗克&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*t7_tv6Ey2ElXQeiAt2XS7g.gif" alt="img" loading="lazy"></p><p>在Groq上运行DeepSeek R1</p><p>GROQ支持<code>DeepSeek-R1-Distill-Llama-70B</code>版本。要使用它，请访问<a href="https://groq.com/%E5%B9%B6%E7%9B%B4%E6%8E%A5%E5%9C%A8%E4%B8%BB%E9%A1%B5%E4%B8%8A%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%9E%8B%E3%80%82" target="_blank" rel="noreferrer">https://groq.com/并直接在主页上运行模型。</a> 另外，您可以通过单击主页右上角的<strong>DEV控制台</strong>按钮在Groq上运行R1模型，如下图所示。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*z-xnWPHT-dlvQc6B-6JA3Q.gif" alt="img" loading="lazy"></p><p>使用Groq Dev Console运行DeepSeek R1</p><h1 id="azure-ai铸造厂" tabindex="-1">Azure AI铸造厂 <a class="header-anchor" href="#azure-ai铸造厂" aria-label="Permalink to &quot;Azure AI铸造厂&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*Q-k_m5wqjLEj3ris38HIgg.gif" alt="img" loading="lazy"></p><p>访问Azure AI Foundry的DeepSeek R1</p><p>如上图所示，您可以在Microsoft的Aure AI Foundry上访问DeepSeek R1的蒸馏版。访问Azure AI Foundry网站以<a href="https://azure.microsoft.com/en-us/products/ai-foundry" target="_blank" rel="noreferrer">开始</a>。</p><p>其他受欢迎LLM托管平台您可以运行DeepSeek R1的蒸馏型号包括以下链接。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*Ah-fLpta18-57s-1" alt="img" loading="lazy"></p><p>deepseek r1一起。</p><ul><li><a href="https://fireworks.ai/" target="_blank" rel="noreferrer">https://fireworks.ai/</a></li><li><a href="https://www.together.ai/" target="_blank" rel="noreferrer">https://www.together.ai/</a></li><li><a href="https://openrouter.ai/" target="_blank" rel="noreferrer">https://openrouter.ai/</a></li><li><a href="https://chatllm.abacus.ai/" target="_blank" rel="noreferrer">https://chatllm.abacus.ai/</a></li><li><a href="https://chutes.ai/" target="_blank" rel="noreferrer">https://chutes.ai/</a></li></ul><h1 id="deepseek-r1和开源模型的未来" tabindex="-1">DeepSeek R1和开源模型的未来 <a class="header-anchor" href="#deepseek-r1和开源模型的未来" aria-label="Permalink to &quot;DeepSeek R1和开源模型的未来&quot;">​</a></h1><p>在本文中，您学会了如何使用<a href="https://getstream.io/blog/best-local-llm-tools/" target="_blank" rel="noreferrer">本地优先权</a>运行DeepSeek R1模型<a href="https://getstream.io/blog/best-local-llm-tools/" target="_blank" rel="noreferrer">LLM</a>Lmstudio，Ollama和Jan等<a href="https://getstream.io/blog/best-local-llm-tools/" target="_blank" rel="noreferrer">工具</a>。您还学会了如何使用可伸缩和企业准备LLM托管平台运行模型。 DeepSeek R1模型是OpenAI O1模型的绝佳替代方法，能够推理完成高度要求和合乎逻辑的任务。</p><p>在撰写本文时，可访问DeepSeek R1模型LLM托管平台，例如Azure <a href="https://azure.microsoft.com/en-us/products/ai-foundry" target="_blank" rel="noreferrer">AI Foundry</a>和<a href="https://groq.com/" target="_blank" rel="noreferrer">Groq</a> 。这些平台确保其托管语言模型的可靠性和安全性。将来，我们希望看到更多的公司和开源开发人员重现DeepSeek R1模型，并为不同的用例提供。另外，许多本地第一LLM工具和托管服务可以支持DeepSeek R1型号及其蒸馏版。</p><h2 id="联系我" tabindex="-1">联系我 <a class="header-anchor" href="#联系我" aria-label="Permalink to &quot;联系我&quot;">​</a></h2><p>最后，推荐大家关注一下开源项目：LangChat，Java生态下的AIGC大模型产品解决方案。</p><ul><li>LangChat产品官网：<a href="https://langchat.cn/" target="_blank" rel="noreferrer">https://langchat.cn/</a></li><li>Github: <a href="https://github.com/TyCoding/langchat" target="_blank" rel="noreferrer">https://github.com/TyCoding/langchat</a></li><li>Gitee: <a href="https://gitee.com/langchat/langchat" target="_blank" rel="noreferrer">https://gitee.com/langchat/langchat</a></li><li>微信：LangchainChat</li></ul><p><img src="http://cdn.tycoding.cn/docs/202502151026673.png" alt="iShot_2025-02-12_12.18.53" loading="lazy"></p></div></div></main><footer class="VPDocFooter" data-v-479a6568 data-v-a9f44413><!--[--><!--]--><div class="edit-info" data-v-a9f44413><!----><div class="last-updated" data-v-a9f44413><p class="VPLastUpdated" data-v-a9f44413 data-v-0500d987>Last updated: <time datetime="2025-02-26T01:05:02.000Z" data-v-0500d987></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-a9f44413><span class="visually-hidden" id="doc-footer-aria-label" data-v-a9f44413>Pager</span><div class="pager" data-v-a9f44413><a class="VPLink link pager-link prev" href="/docs/other/the-ai-web-search-landscape.html" data-v-a9f44413><!--[--><span class="desc" data-v-a9f44413>Previous page</span><span class="title" data-v-a9f44413>AI搜索引擎生态全景</span><!--]--></a></div><div class="pager" data-v-a9f44413><a class="VPLink link pager-link next" href="/docs/other/top11-ai-chat-ui-for-developers.html" data-v-a9f44413><!--[--><span class="desc" data-v-a9f44413>Next page</span><span class="title" data-v-a9f44413>11个开发人员必备AI聊天界面</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"docs_deploy_deploy.md\":\"Dg2bS27a\",\"docs_exercise_langchat-deepseek-r1.md\":\"BG1HS0Jq\",\"docs_exercise_oss-minio.md\":\"BKGFqqWT\",\"docs_exercise_rag.md\":\"YedSmvND\",\"docs_other_bank.md\":\"5tiAkFLT\",\"docs_other_chunking-strategies.md\":\"gV_LewAr\",\"docs_other_claude-3-7-sonnet.md\":\"Dj1Hhibl\",\"docs_other_deepseek-r1-architecture-and-training.md\":\"0Z6H9Kbq\",\"docs_other_deepseek-r1-distilled-models.md\":\"4nK05JS_\",\"docs_other_deepseek-r1-reasoning-capabilities-analysis.md\":\"B5CK-D6e\",\"docs_other_deepseek-r1-tuning.md\":\"CdRsqumj\",\"docs_other_distill-deepseek-r1-into-your-model.md\":\"DdEwVv1R\",\"docs_other_guide-getting-started-with-cursor-and-deepseek-r1.md\":\"CrF2GZkG\",\"docs_other_hardware-guide-for-llm-training-and-fine-tuning.md\":\"CyLRPjt8\",\"docs_other_markitdown-a-deep-dive.md\":\"Cs6UPOgy\",\"docs_other_reasoning-modes-vs-other-ai-models.md\":\"BmYH1TUj\",\"docs_other_the-ai-web-search-landscape.md\":\"C4xGfer5\",\"docs_other_top11-ai-chat-ui-for-developers.md\":\"CSnixW_I\",\"docs_other_top8-on-premise-plans-for-deepseek-r1.md\":\"BroA2pse\",\"docs_other_vllm-llm-local-inference-library.md\":\"7uM8sIzs\",\"docs_other_vllm-ollama-comprehensive-comparison.md\":\"D9IVeAkT\",\"docs_other_vllm-vs-ollama.md\":\"BRFYvY27\",\"docs_start_environment.md\":\"DkSgePUm\",\"docs_start_getting-started.md\":\"B8WJQYY8\",\"docs_start_introduce.md\":\"CgbmexuX\",\"docs_start_knowledge.md\":\"Ce41O1tK\",\"docs_start_login.md\":\"DWOURVt-\",\"docs_start_models-proxy.md\":\"6b6woVJN\",\"docs_start_models.md\":\"Ds4X4F2M\",\"docs_start_questions.md\":\"AMWgx7AD\",\"index.md\":\"n9TEBaM7\",\"readme.md\":\"DKy5OORU\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"LangChat Docs\",\"description\":\"LangChat Project Document\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":{\"level\":\"deep\"},\"search\":{\"provider\":\"local\"},\"nav\":[{\"text\":\"LangChat\",\"link\":\"/\"},{\"text\":\"LangChat文档\",\"link\":\"/docs/exercise/langchat-deepseek-r1\",\"activeMatch\":\"/docs\"},{\"text\":\"在线预览\",\"items\":[{\"text\":\"LangChat官网\",\"link\":\"https://langchat.cn/\"},{\"text\":\"LangChat后台预览\",\"link\":\"http://backend.langchat.cn/\"},{\"text\":\"LangChat LLM Ops\",\"link\":\"http://llm.langchat.cn\"},{\"text\":\"LangChat UPMS Ops\",\"link\":\"http://upms.langchat.cn\"}]}],\"sidebar\":{\"/docs\":[{\"text\":\"LangChat实战\",\"items\":[{\"text\":\"DeepSeek-R1实战\",\"link\":\"/docs/exercise/langchat-deepseek-r1\"},{\"text\":\"使用Minio作为OSS\",\"link\":\"/docs/exercise/oss-minio\"},{\"text\":\"LLM-RAG基础概念\",\"link\":\"/docs/exercise/rag\"}]},{\"text\":\"LangChat配置\",\"items\":[{\"text\":\"LangChat介绍\",\"link\":\"/docs/start/introduce\"},{\"text\":\"环境准备\",\"link\":\"/docs/start/environment\"},{\"text\":\"快速开始\",\"link\":\"/docs/start/getting-started\"},{\"text\":\"登录LangChat\",\"link\":\"/docs/start/login\"},{\"text\":\"模型配置\",\"link\":\"/docs/start/models\"},{\"text\":\"模型代理\",\"link\":\"/docs/start/models-proxy\"},{\"text\":\"知识库\",\"link\":\"/docs/start/knowledge\"},{\"text\":\"常见问题\",\"link\":\"/docs/start/questions\"}]},{\"text\":\"LangChat部署\",\"items\":[{\"text\":\"LangChat部署教程\",\"link\":\"/docs/deploy/deploy\"}]},{\"text\":\"推荐阅读\",\"items\":[{\"text\":\"大模型RAG中的分块策略\",\"link\":\"/docs/other/chunking-strategies\"},{\"text\":\"Claude 3.7 Sonnet强势来袭\",\"link\":\"/docs/other/claude-3-7-sonnet\"},{\"text\":\"DeepSeek R1架构和训练过程图解\",\"link\":\"/docs/other/deepseek-r1-architecture-and-training\"},{\"text\":\"DeepSeek-R1蒸馏模型\",\"link\":\"/docs/other/deepseek-r1-distilled-models\"},{\"text\":\"DeepSeek-R1的推理能力分析\",\"link\":\"/docs/other/deepseek-r1-reasoning-capabilities-analysis\"},{\"text\":\"DeepSeek-R1微调指南\",\"link\":\"/docs/other/deepseek-r1-tuning\"},{\"text\":\"蒸馏DeepSeek-R1到自己的模型\",\"link\":\"/docs/other/distill-deepseek-r1-into-your-model\"},{\"text\":\"Cursor + DeepSeek R1 使用指南\",\"link\":\"/docs/other/guide-getting-started-with-cursor-and-deepseek-r1\"},{\"text\":\"大模型训练/微调硬件指南\",\"link\":\"/docs/other/hardware-guide-for-llm-training-and-fine-tuning\"},{\"text\":\"MarkItDown深入研究\",\"link\":\"/docs/other/markitdown-a-deep-dive\"},{\"text\":\"推理模型 vs. 其他AI模型\",\"link\":\"/docs/other/reasoning-modes-vs-other-ai-models\"},{\"text\":\"AI搜索引擎生态全景\",\"link\":\"/docs/other/the-ai-web-search-landscape\"},{\"text\":\"8个DeepSeek-R1私有化部署方案\",\"link\":\"/docs/other/top8-on-premise-plans-for-deepseek-r1\"},{\"text\":\"11个开发人员必备AI聊天界面\",\"link\":\"/docs/other/top11-ai-chat-ui-for-developers\"},{\"text\":\"vLLM 大模型本地推理库\",\"link\":\"/docs/other/vllm-llm-local-inference-library\"},{\"text\":\"vLLM/ollama综合对比\",\"link\":\"/docs/other/vllm-ollama-comprehensive-comparison\"},{\"text\":\"VLLM vs. Ollama\",\"link\":\"/docs/other/vllm-vs-ollama\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/TyCoding/langchat\"}]},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>