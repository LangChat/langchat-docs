import{_ as n,c as s,o as l,ag as e}from"./chunks/framework.ByciF0Oj.js";const d=JSON.parse('{"title":"什么是分块？","description":"","frontmatter":{},"headers":[],"relativePath":"docs/other/chunking-strategies.md","filePath":"docs/other/chunking-strategies.md","lastUpdated":1740531902000}'),i={name:"docs/other/chunking-strategies.md"};function t(p,a,o,c,r,u){return l(),s("div",null,a[0]||(a[0]=[e(`<h2 id="大模型rag中的分块策略" tabindex="-1">大模型RAG中的分块策略 <a class="header-anchor" href="#大模型rag中的分块策略" aria-label="Permalink to &quot;大模型RAG中的分块策略&quot;">​</a></h2><p>分块策略在检索增强生成（RAG）方法中起着至关重要的作用，它使文档能够被划分为可管理的部分，同时保持上下文。每种方法都有其特定的优势，适用于特定的用例。</p><p>将大型数据文件拆分为更易于管理的段是提高LLM应用效率的最关键步骤之一。目标是向LLM提供完成特定任务所需的确切信息，不多也不少。</p><p>“我的解决方案中应该采用何种合适的分块策略”是LLM实践者在构建高级 RAG 解决方案时必须做出的初始和基本决策之一。</p><h3 id="关于langchat" tabindex="-1">关于LangChat <a class="header-anchor" href="#关于langchat" aria-label="Permalink to &quot;关于LangChat&quot;">​</a></h3><p><strong>LangChat</strong> 是Java生态下企业级AIGC项目解决方案，集成RBAC和AIGC大模型能力，帮助企业快速定制AI知识库、企业AI机器人。</p><p><strong>支持的AI大模型：</strong> Gitee AI / 阿里通义 / 百度千帆 / DeepSeek / 抖音豆包 / 智谱清言 / 零一万物 / 讯飞星火 / OpenAI / Gemini / Ollama / Azure / Claude 等大模型。</p><ul><li>官网地址：<a href="http://langchat.cn/" target="_blank" rel="noreferrer">http://langchat.cn/</a></li></ul><p><strong>开源地址：</strong></p><ul><li>Gitee：<a href="https://gitee.com/langchat/langchat" target="_blank" rel="noreferrer">https://gitee.com/langchat/langchat</a></li><li>Github：<a href="https://github.com/tycoding/langchat" target="_blank" rel="noreferrer">https://github.com/tycoding/langchat</a></li></ul><p><img src="http://cdn.tycoding.cn/docs/202502151026673.png" alt="iShot_2025-02-12_12.18.53" loading="lazy"></p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*VhFr2tr_FbTjzNyNv5DjWw.png" alt="img" loading="lazy"></p><h1 id="什么是分块" tabindex="-1">什么是分块？ <a class="header-anchor" href="#什么是分块" aria-label="Permalink to &quot;什么是分块？&quot;">​</a></h1><p>分块涉及将文本划分为可管理的单元或“块”，以实现高效处理。这种分割对于语义搜索、信息检索和生成式 AI 应用等任务至关重要。每个块都保留上下文和语义完整性，以确保结果连贯。</p><h1 id="_2-分块技术及其策略" tabindex="-1">2. 分块技术及其策略 <a class="header-anchor" href="#_2-分块技术及其策略" aria-label="Permalink to &quot;2. 分块技术及其策略&quot;">​</a></h1><p>各种分块技术根据文本结构和应用需求满足特定需求：</p><ul><li>固定长度分块：根据标记、单词或字符将文本分割成统一的大小。这种方法计算效率高，但可能在边界处切断有意义的上下文。</li><li>基于句子的分块：按句子分割文本，保留语法和上下文完整性。非常适合对话模型，但可能对较长的文本效率不高。</li><li>基于段落的分块：按段落分组文本，保持主题上下文。适用于结构化文档，但可能对精细调整的任务失去粒度。</li><li>语义分块：专注于按意义分组文本，而不是结构。这确保了语义连贯性，但增加了计算开销，因为它需要深入的语言理解。</li><li>滑动窗口分块：使用重叠窗口对文本进行分段，减少块边界处的信息损失。它确保更好的上下文保留，但会增加内存和处理成本。</li><li>文档分块：将整个文档视为一个单一块。这种方法对于保持整体上下文有效，但由于内存限制，可能不适用于大型文本。</li></ul><h1 id="_3-分块优化关键策略" tabindex="-1">3. 分块优化关键策略 <a class="header-anchor" href="#_3-分块优化关键策略" aria-label="Permalink to &quot;3. 分块优化关键策略&quot;">​</a></h1><p>为了最大化分块的优势，采用以下策略：</p><ul><li>重叠块：包括块之间的某些重叠可以确保在段落之间不会丢失关键信息。这对于需要无缝过渡的任务尤其重要，如对话生成或摘要。</li><li>动态块大小：根据模型的容量或文本的复杂性调整块大小可以提升性能。较小的块适合 BERT 等模型，而较大的块适用于需要更广泛上下文的生成任务。</li><li>：递归或多级分块允许处理复杂的文本结构，例如将文档拆分为章节、节和段落。</li><li>向量化的对齐：分块技术的选择对检索系统中的向量表示有显著影响。句子转换器和 BERT 或 GPT 等嵌入通常用于与分块粒度对齐的最佳向量化</li></ul><h1 id="_4-优点与局限性" tabindex="-1">4. 优点与局限性 <a class="header-anchor" href="#_4-优点与局限性" aria-label="Permalink to &quot;4. 优点与局限性&quot;">​</a></h1><ul><li><strong>好处：</strong></li><li>增强上下文理解。</li><li>支持 RAG 系统中高效的索引和检索。</li><li>保持生成模型中更好的准确性，语义连贯性。</li><li>限制：</li><li>计算上对语义和重叠分块较为昂贵。</li><li>需要调整以平衡上下文保留和处理效率。</li></ul><h1 id="_5-应用场景" tabindex="-1">5. 应用场景 <a class="header-anchor" href="#_5-应用场景" aria-label="Permalink to &quot;5. 应用场景&quot;">​</a></h1><p>分词在以下方面被广泛使用：</p><ul><li>检索系统：在搜索引擎或聊天机器人中检索回答查询的相关片段。</li><li>生成模型：保持文本生成的上下文连贯。</li><li>学术和法律研究：确保对结构化和复杂文档进行详细、有意义的分段。</li></ul><p>通过采用适当的分块策略，从业者可以提升检索和生成系统的性能，在计算资源和上下文准确性之间取得平衡。</p><h1 id="_1-固定长度分块" tabindex="-1">1. 固定长度分块 <a class="header-anchor" href="#_1-固定长度分块" aria-label="Permalink to &quot;1. 固定长度分块&quot;">​</a></h1><p>固定长度分块将文本分割成指定字符数或词数的块。这种方法简单直接，但往往存在将有意义的内容分割开的风险，导致上下文丢失。</p><p>如何工作：<strong>如何工作</strong></p><ul><li>该方法根据预定义的长度（例如，单词数、标记或字符数）将文本划分为均匀的块。</li><li>例如，一个包含 100 个单词的段落可能被分成十个 10 个单词的片段。</li></ul><p>优势：</p><ul><li>简洁性与计算效率。</li><li>适用于结构化文本或当上下文边界不是关键时。</li></ul><p>缺点：</p><ul><li>可能会在块之间分割句子或想法，导致语义连贯性丧失。</li></ul><p>示例：<strong>示例</strong>：</p><ul><li>文本分块通过将文本分解成部分来提高检索。</li><li>固定长度分块（每块 10 个字符）：</li><li>块 1：“Chunking i”</li><li>块 2：“提高 re”</li><li>块 3：“通过”检索</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Input: &quot;The quick brown fox jumps over the lazy dog. It is a bright sunny day.&quot;</span></span>
<span class="line"><span>Chunk Size: 10 characters</span></span>
<span class="line"><span>Chunks:</span></span>
<span class="line"><span>  1. &quot;The quick &quot;</span></span>
<span class="line"><span>  2. &quot;brown fox &quot;</span></span>
<span class="line"><span>  3. &quot;jumps over&quot;</span></span>
<span class="line"><span>  4. &quot; the lazy&quot;</span></span>
<span class="line"><span>  5. &quot; dog. It&quot;</span></span>
<span class="line"><span>  6. &quot; is a bri&quot;</span></span>
<span class="line"><span>  7. &quot;ght sunny&quot;</span></span>
<span class="line"><span>  8. &quot; day.&quot;</span></span></code></pre></div><ul><li>影响：分割句子或思想会导致语义连贯性丧失。</li></ul><p>代码示例</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def fixed_length_chunk(text, size):</span></span>
<span class="line"><span>    return [text[i:i+size] for i in range(0, len(text), size)]</span></span></code></pre></div><h1 id="_2-语义块切分" tabindex="-1">2. 语义块切分 <a class="header-anchor" href="#_2-语义块切分" aria-label="Permalink to &quot;2. 语义块切分&quot;">​</a></h1><p>文本根据语义连贯性分成块，确保每个块都是一个有意义的单元。这通常需要使用嵌入来找到逻辑边界。</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*eZ_l7rinqtWWAlBH.png" alt="img" loading="lazy"></p><p>如何工作：<strong>如何工作</strong></p><ul><li>文本根据语义连贯性而非固定大小进行划分。</li><li>使用自然语言理解（NLP）来识别逻辑断点，如句子或主题边界。</li></ul><p>优势：</p><ul><li>保留每个片段的意义和上下文。</li><li>提升检索增强生成（RAG）任务的准确性。</li></ul><p>缺点：</p><ul><li>计算成本高，因为它需要语义解析。</li></ul><p>示例：<strong>示例</strong>：</p><ul><li>AI 研究涵盖各种主题。机器学习专注于模式。</li><li>语义块：</li><li>块 1：“人工智能研究涵盖各种主题。”</li><li>机器学习专注于模式。</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Input: &quot;The quick brown fox jumps over the lazy dog. It is a bright sunny day.&quot;</span></span>
<span class="line"><span>Chunks:</span></span>
<span class="line"><span>  1. &quot;The quick brown fox jumps over the lazy dog.&quot;</span></span>
<span class="line"><span>  2. &quot;It is a bright sunny day.&quot;</span></span></code></pre></div><ul><li>影响：通过保留信息的逻辑流程来提高检索准确性。</li><li>代码示例</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from sentence_transformers import SentenceTransformer</span></span>
<span class="line"><span></span></span>
<span class="line"><span>def semantic_chunk(text, max_tokens, model):</span></span>
<span class="line"><span>    sentences = text.split(&#39;. &#39;)</span></span>
<span class="line"><span>    chunks, current_chunk = [], &quot;&quot;</span></span>
<span class="line"><span>    for sentence in sentences:</span></span>
<span class="line"><span>        if len(current_chunk) + len(sentence) &lt;= max_tokens:</span></span>
<span class="line"><span>            current_chunk += sentence + &quot;. &quot;</span></span>
<span class="line"><span>        else:</span></span>
<span class="line"><span>            chunks.append(current_chunk.strip())</span></span>
<span class="line"><span>            current_chunk = sentence + &quot;. &quot;</span></span>
<span class="line"><span>    if current_chunk:</span></span>
<span class="line"><span>        chunks.append(current_chunk.strip())</span></span>
<span class="line"><span>    return chunks</span></span></code></pre></div><h1 id="_3-递归字符分块" tabindex="-1">3. 递归字符分块 <a class="header-anchor" href="#_3-递归字符分块" aria-label="Permalink to &quot;3. 递归字符分块&quot;">​</a></h1><p>初始块基于字符限制创建。如果它们太大，则递归地分成更小的、具有语义意义的单元（例如，句子）。</p><p>如何工作：<strong>如何工作</strong></p><ul><li>最初，根据字符限制（例如，500 个字符）创建大块内容。</li><li>如果一个块超过了限制，它将被递归地分割成更小的有意义的单位，例如句子。</li></ul><p>优势：</p><ul><li>保留语义完整性，同时遵守尺寸限制。</li><li>非常适合存在 API 限制的情况（例如，OpenAI 的令牌限制）。</li></ul><p>缺点：</p><ul><li>递归处理会增加计算时间。</li></ul><p>示例：<strong>示例</strong>：</p><ul><li>文本分块将文本分解成更小的部分。此方法增强了检索。</li><li>递归字符限制（20 个字符）：</li><li>文本块 1：“分块处理文本”</li><li>块 2：“分成更小的部分。”</li><li>块 3：“此方法增强”</li><li>块 4：“检索。”</li></ul><p>示例：<strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Input: &quot;The quick brown fox jumps over the lazy dog. It is a bright sunny day.&quot;</span></span>
<span class="line"><span>Step 1: Chunk by character size (50).</span></span>
<span class="line"><span>Step 2: Further divide large chunks into sentences.</span></span>
<span class="line"><span>Chunks:</span></span>
<span class="line"><span>  1. &quot;The quick brown fox jumps over the lazy dog.&quot;</span></span>
<span class="line"><span>  2. &quot;It is a bright sunny day.&quot;</span></span></code></pre></div><p>影响：平衡块大小和连贯性。</p><p>代码示例</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def recursive_chunk(text, char_limit):</span></span>
<span class="line"><span>    if len(text) &lt;= char_limit:</span></span>
<span class="line"><span>        return [text]</span></span>
<span class="line"><span>    midpoint = len(text) // 2</span></span>
<span class="line"><span>    for i in range(midpoint, len(text)):</span></span>
<span class="line"><span>        if text[i] in &#39;.!?&#39;:</span></span>
<span class="line"><span>            return [text[:i+1].strip()] + recursive_chunk(text[i+1:].strip(), char_limit)</span></span></code></pre></div><h1 id="_4-自适应分块" tabindex="-1">4. 自适应分块 <a class="header-anchor" href="#_4-自适应分块" aria-label="Permalink to &quot;4. 自适应分块&quot;">​</a></h1><p>动态调整块大小，根据内容的复杂度或重要性，利用自然语言处理技术识别逻辑终点。</p><p>如何工作：<strong>如何工作</strong></p><ul><li>动态调整块大小，基于内容复杂度。</li><li>使用先进的自然语言处理技术来查找逻辑端点。</li></ul><p>优势：</p><ul><li>平衡计算效率和语义连贯性。</li><li>有效处理复杂和可变长度的内容。</li></ul><p>缺点：</p><ul><li>实施复杂性。</li></ul><p>示例：<strong>示例</strong>：</p><ul><li>“简单想法适合小块。复杂概念需要更大的块。”</li><li>自适应块</li><li>块 1：“简单想法适合小块。”</li><li>块 2：“复杂概念需要更大的块。”</li></ul><p>示例：<strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Input: &quot;The quick brown fox jumps over the lazy dog. It is a bright sunny day.&quot;</span></span>
<span class="line"><span>Output:</span></span>
<span class="line"><span>  1. &quot;The quick brown fox jumps over the lazy dog.&quot;</span></span>
<span class="line"><span>  2. &quot;It is a bright sunny day.&quot;</span></span></code></pre></div><p>影响：适应不同类型的文档，提高混合内容情况下的性能。</p><p><strong>代码示例</strong></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def adaptive_chunk(text, nlp_model):</span></span>
<span class="line"><span>    doc = nlp_model(text)</span></span>
<span class="line"><span>    chunks = []</span></span>
<span class="line"><span>    for sent in doc.sents:</span></span>
<span class="line"><span>        chunks.append(sent.text.strip())</span></span>
<span class="line"><span>    return chunks</span></span></code></pre></div><h1 id="_5-混合分块" tabindex="-1">5. 混合分块 <a class="header-anchor" href="#_5-混合分块" aria-label="Permalink to &quot;5. 混合分块&quot;">​</a></h1><ul><li>解释：结合固定长度和语义分块，允许在块大小上保持灵活性，同时保持语义连贯性。</li></ul><p>如何工作：<strong>如何工作</strong></p><ul><li>结合固定大小和语义分块策略。</li><li>允许在保持上下文的同时调整块大小。</li></ul><p>优势：</p><ul><li>可定制以适应特定应用。</li><li>平衡精度与效率。</li></ul><p>缺点：</p><ul><li>需要仔细调整以避免冗余或失真。</li></ul><p>示例：<strong>示例</strong>：</p><ul><li>“分块提高检索效率。灵活性对于精确度至关重要。”</li><li>混合块：</li><li>块 1：“分块提高检索。”</li><li>块 2：“灵活性对精度至关重要。”</li></ul><p>示例：<strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Input: &quot;The quick brown fox jumps over the lazy dog. It is a bright sunny day.&quot;</span></span>
<span class="line"><span>Chunk Size: 10 words</span></span>
<span class="line"><span>Chunks:</span></span>
<span class="line"><span>  1. &quot;The quick brown fox jumps over the lazy dog.&quot;</span></span>
<span class="line"><span>  2. &quot;It is a bright sunny day.&quot;</span></span></code></pre></div><ul><li>影响：针对既需要上下文又需要计算效率的系统进行了优化。</li></ul><p>代码示例</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def hybrid_chunk(text, word_limit, semantic=True):</span></span>
<span class="line"><span>    words = text.split()</span></span>
<span class="line"><span>    chunks = []</span></span>
<span class="line"><span>    for i in range(0, len(words), word_limit):</span></span>
<span class="line"><span>        chunk = &quot; &quot;.join(words[i:i+word_limit])</span></span>
<span class="line"><span>        if semantic and chunk[-1] not in &#39;.!?&#39;:</span></span>
<span class="line"><span>            chunk += &#39;.&#39;</span></span>
<span class="line"><span>        chunks.append(chunk.strip())</span></span>
<span class="line"><span>    return chunks</span></span></code></pre></div><h1 id="_6-重叠分块" tabindex="-1">6. 重叠分块 <a class="header-anchor" href="#_6-重叠分块" aria-label="Permalink to &quot;6. 重叠分块&quot;">​</a></h1><p>块重叠一定间距，确保边界处不丢失上下文。</p><p>如何工作：<strong>如何工作</strong></p><ul><li>创建重叠块以保留边界之间的上下文。</li><li>确保一个块中的关键思想不会在块之间丢失。</li></ul><p>优势：</p><ul><li>保留更多上下文。</li><li>提升检索准确性。</li></ul><p>缺点：</p><ul><li>冗余增加内存使用。</li></ul><p>示例：<strong>示例</strong>：</p><ul><li>文本分块通过将文本分解成部分来提高检索。</li><li>重叠块（5 词重叠）：</li><li>块 1：“分块通过分割提高检索”</li><li>块 2：“通过将文本拆分来检索”</li><li>块 3：“将文本拆分成部分。”</li></ul><p>示例：<strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Input: &quot;The quick brown fox jumps over the lazy dog. It is a bright sunny day.&quot;</span></span>
<span class="line"><span>Overlap: 5 words</span></span>
<span class="line"><span>Chunks:</span></span>
<span class="line"><span>  1. &quot;The quick brown fox jumps over the lazy&quot;</span></span>
<span class="line"><span>  2. &quot;fox jumps over the lazy dog. It is a&quot;</span></span>
<span class="line"><span>  3. &quot;dog. It is a bright sunny day.&quot;</span></span></code></pre></div><ul><li>影响：跨边界保持上下文，提高检索质量。</li><li>代码示例</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def overlapping_chunk(text, size, overlap):</span></span>
<span class="line"><span>    words = text.split()</span></span>
<span class="line"><span>    chunks = []</span></span>
<span class="line"><span>    for i in range(0, len(words), size - overlap):</span></span>
<span class="line"><span>        chunks.append(&quot; &quot;.join(words[i:i+size]))</span></span>
<span class="line"><span>    return chunks</span></span></code></pre></div><h1 id="_7-字符文本分割" tabindex="-1">7. 字符文本分割 <a class="header-anchor" href="#_7-字符文本分割" aria-label="Permalink to &quot;7. 字符文本分割&quot;">​</a></h1><p>如何工作：<strong>如何工作</strong></p><ul><li>根据特定的字符限制分割文本。</li></ul><p>优势：</p><ul><li>快速且直接。</li><li>适用于具有令牌或字符限制的系统。</li></ul><p>缺点：</p><ul><li>风险在于字符在单词或句子中间掉落时破坏意义。</li></ul><h1 id="_8-使用-langchain-进行自动文本分割" tabindex="-1">8. 使用 LangChain 进行自动文本分割 <a class="header-anchor" href="#_8-使用-langchain-进行自动文本分割" aria-label="Permalink to &quot;8. 使用 LangChain 进行自动文本分割&quot;">​</a></h1><p>如何工作：<strong>如何工作</strong></p><ul><li>使用 LangChain 内置的<code>TextSplitter</code>类来自动化分块。</li><li>根据文本类型和内容结构进行适配。</li></ul><p>优势：</p><ul><li>简化处理流程。</li><li>支持各种分块配置。</li></ul><h1 id="_9-递归字符文本分割" tabindex="-1">9. 递归字符文本分割 <a class="header-anchor" href="#_9-递归字符文本分割" aria-label="Permalink to &quot;9. 递归字符文本分割&quot;">​</a></h1><p>如何工作：<strong>如何工作</strong></p><ul><li>递归方法类似于递归字符分块，但专为分词文本设计。</li></ul><h1 id="_10-文档特定拆分" tabindex="-1">10. 文档特定拆分 <a class="header-anchor" href="#_10-文档特定拆分" aria-label="Permalink to &quot;10. 文档特定拆分&quot;">​</a></h1><p>如何工作：<strong>如何工作</strong></p><ul><li>利用特定领域的拆分器（例如，<code>MarkdownSplitter</code>、<code>PythonCodeTextSplitter</code>）来处理专业文档。</li></ul><p>优势：</p><ul><li>自定义各种格式的处理。</li><li>增强特定领域检索。</li></ul><h1 id="_11-基于嵌入的语义分块" tabindex="-1">11. 基于嵌入的语义分块 <a class="header-anchor" href="#_11-基于嵌入的语义分块" aria-label="Permalink to &quot;11. 基于嵌入的语义分块&quot;">​</a></h1><p>如何工作：<strong>如何工作</strong></p><ul><li>使用语义嵌入将文本划分为连贯的片段。</li><li>将块与向量表示对齐以增强搜索。</li></ul><h1 id="_12-代理分块" tabindex="-1">12. 代理分块 <a class="header-anchor" href="#_12-代理分块" aria-label="Permalink to &quot;12. 代理分块&quot;">​</a></h1><p>代理分块关注逻辑命题或连贯的组群，将每个分块分解成有意义的行或组。</p><h2 id="基于命题的词块化" tabindex="-1">基于命题的词块化 <a class="header-anchor" href="#基于命题的词块化" aria-label="Permalink to &quot;基于命题的词块化&quot;">​</a></h2><ul><li>解释：每个块代表一个逻辑命题，独立存在，具有完整的意义。</li><li>示例：<strong>示例</strong>：</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>Input: &quot;The quick brown fox jumps. The lazy dog sleeps.&quot;</span></span>
<span class="line"><span>Chunks:</span></span>
<span class="line"><span>  1. &quot;The quick brown fox jumps.&quot;</span></span>
<span class="line"><span>  2. &quot;The lazy dog sleeps.&quot;</span></span></code></pre></div><p>影响：适用于结构化和基于规则的文本。</p><h2 id="基于分组的分块" tabindex="-1">基于分组的分块 <a class="header-anchor" href="#基于分组的分块" aria-label="Permalink to &quot;基于分组的分块&quot;">​</a></h2><ul><li>解释：根据代理驱动的启发式方法将相关块组合成连贯的单元。</li><li>代码示例</li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def agentic_chunk(text):</span></span>
<span class="line"><span>    lines = text.split(&#39;. &#39;)</span></span>
<span class="line"><span>    chunks = [line.strip() + &#39;.&#39; for line in lines if line]</span></span>
<span class="line"><span>    return chunks</span></span></code></pre></div><h1 id="代理分块-详细解释" tabindex="-1">代理分块：详细解释 <a class="header-anchor" href="#代理分块-详细解释" aria-label="Permalink to &quot;代理分块：详细解释&quot;">​</a></h1><p><img src="https://miro.medium.com/v2/resize:fit:1400/0*eYoAJxEDa5uUKVu2.png" alt="img" loading="lazy"></p><p>代理分块是一种复杂的文本分割策略，旨在确保文本块保持其语义连贯性并传达有意义的信息。它采用两种主要子策略：</p><p><img src="https://miro.medium.com/v2/resize:fit:1400/1*2r7xsoPZx6alNY0t5kH9QQ.png" alt="img" loading="lazy"></p><h1 id="基于命题的词块化-1" tabindex="-1">基于命题的词块化 <a class="header-anchor" href="#基于命题的词块化-1" aria-label="Permalink to &quot;基于命题的词块化&quot;">​</a></h1><p>定义 基于命题的切分关注将文本分割成独立的块，其中每个部分代表一个命题或完整的想法。命题通常是一个句子或句子的一部分，传达一个完整的思想或陈述。</p><p>工作策略</p><p>命题识别</p><ul><li>使用自然语言处理（NLP）技术，对文本进行分析以识别逻辑或语法命题。</li><li>例如，由连词或标点符号连接的从句可能被分成不同的命题。</li></ul><p>分割过程</p><ul><li>每个块都是为了确保它形成一个完整且独立的陈述，即使在孤立的情况下也能保留其意义。</li></ul><p>语义完整性</p><ul><li>该过程避免了以留下不完整或模糊信息的方式分割</li></ul><p>示例：<strong>示例</strong>：</p><ul><li>人工智能（AI）正在迅速发展，它正在改变着行业。</li><li>基于命题的词块</li></ul><ol><li>人工智能（AI）正在迅速发展。</li><li>它正在改变行业。</li></ol><p>应用</p><ul><li>在需要精确事实检索的系统中有用，例如知识库、问答系统和学术文本处理。</li><li>增强信息检索的粒度，确保每个片段提供完整的知识。</li></ul><h1 id="_2-使用代理分块器进行分组分块" tabindex="-1">2. 使用代理分块器进行分组分块 <a class="header-anchor" href="#_2-使用代理分块器进行分组分块" aria-label="Permalink to &quot;2. 使用代理分块器进行分组分块&quot;">​</a></h1><p>定义 将信息分组成簇，通过将命题或句子分组到逻辑上、语义上一致的单位。目标是保持更广泛的上下文，同时将文本划分为可管理的块。</p><p>工作策略</p><p>识别关系</p><p>自然语言处理技术，如语义相似度和主题建模，被用于检测命题或句子之间的关系。</p><p>块形成：</p><p>相关命题被组合成一个单独的块。这可能是基于共享的主题、引用或逻辑流程。</p><p>尺寸优化</p><p>确保分组块不超过预定义的大小限制（例如，语言模型中的标记或字符限制）。</p><p>示例：<strong>示例</strong>：</p><ul><li>“人工智能正在迅速发展。它正在改变医疗保健和金融等行业。机器学习是人工智能的关键组成部分。”</li><li>分组块</li><li>块 1：“人工智能正在迅速发展。它正在改变医疗保健和金融等行业。”</li><li>机器学习是人工智能的关键组成部分。</li></ul><p>应用</p><ul><li>用于检索增强生成（RAG）系统，以生成保持更广泛上下文的具有意义的响应。</li><li>非常适合文档摘要，其中块之间的主题一致性至关重要。</li></ul><h1 id="代理分块的好处" tabindex="-1">代理分块的好处 <a class="header-anchor" href="#代理分块的好处" aria-label="Permalink to &quot;代理分块的好处&quot;">​</a></h1><p>语义一致性</p><ul><li>确保每个片段都包含一个有意义的独立观点或语义上连贯的观点组。</li></ul><p>改进检索准确性</p><ul><li>通过关注逻辑单元，检索系统可以更好地与用户查询对齐。</li></ul><p>上下文保留：</p><ul><li>将块分组保留了多行推理任务所需的上下文。</li></ul><p>灵活性</p><ul><li>代理分块适应性强，适用于各种用例，从细粒度事实核查到更广泛的主题摘要。</li></ul><h1 id="挑战" tabindex="-1">挑战 <a class="header-anchor" href="#挑战" aria-label="Permalink to &quot;挑战&quot;">​</a></h1><p>计算开销</p><ul><li>该过程涉及语义分析和自然语言处理计算，可能需要大量资源。</li></ul><p>《块大小调整》</p><ul><li>在粒度与上下文保留之间取得平衡需要仔细调整。</li></ul><h1 id="代码演示" tabindex="-1">代码演示 <a class="header-anchor" href="#代码演示" aria-label="Permalink to &quot;代码演示&quot;">​</a></h1><h2 id="设置环境" tabindex="-1">设置环境 <a class="header-anchor" href="#设置环境" aria-label="Permalink to &quot;设置环境&quot;">​</a></h2><p>所需库使用以下命令安装：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip install -U chromadb langchain llama-index langchain_experimental langchain_openai</span></span></code></pre></div><p>关键模块如用于美观打印的<code>rich</code>、用于文档和模型管理的<code>langchain</code>以及用于集成的<code>langchain_community</code>已被导入。使用 Mistral 模型初始化了本地LLM实例的<code>ChatOllama</code>类。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>local_llm = ChatOllama(model=&quot;mistral&quot;)</span></span></code></pre></div><h2 id="_2-rag-实现" tabindex="-1">2. RAG 实现 <a class="header-anchor" href="#_2-rag-实现" aria-label="Permalink to &quot;2. RAG 实现&quot;">​</a></h2><p>RAG 函数使用一个向量存储（<code>色度</code>）和基于检索的提示策略。</p><ol><li>嵌入式初始化：<code>OllamaEmbeddings</code>模型生成文本嵌入，以实现高效的存储和检索。</li><li>检索器设置：向量存储作为检索器，根据查询搜索相关片段。</li><li>提示模板：一个自定义模板为LLM生成相关答案的问题和上下文进行框架。</li></ol><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def rag(chunks, collection_name):</span></span>
<span class="line"><span>    vectorstore = Chroma.from_documents(</span></span>
<span class="line"><span>        documents=documents,</span></span>
<span class="line"><span>        collection_name=collection_name,</span></span>
<span class="line"><span>        embedding=embeddings.ollama.OllamaEmbeddings(model=&#39;nomic-embed-text&#39;),</span></span>
<span class="line"><span>    )</span></span>
<span class="line"><span>    retriever = vectorstore.as_retriever()</span></span>
<span class="line"><span>    ...</span></span>
<span class="line"><span>    chain.invoke(&quot;What is the use of Text Splitting?&quot;)</span></span></code></pre></div><h2 id="_3-文本分割技术" tabindex="-1">3. 文本分割技术 <a class="header-anchor" href="#_3-文本分割技术" aria-label="Permalink to &quot;3. 文本分割技术&quot;">​</a></h2><p><strong>字符文本分割</strong></p><p>文本手动分割成 35 个字符大小的块。或者，<code>CharacterTextSplitter</code> 通过可选参数如 <code>chunk_size</code>、<code>chunk_overlap</code> 和 <code>separator</code> 自动化此过程。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>text_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=0)</span></span>
<span class="line"><span>documents = text_splitter.create_documents([text])</span></span></code></pre></div><p><strong>递归字符文本分割</strong></p><p>这种方法智能地使用多个分隔符（例如，换行符、空格）来分割文本，以保持语义连贯。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>text_splitter = RecursiveCharacterTextSplitter(chunk_size=65, chunk_overlap=0)</span></span>
<span class="line"><span>documents = text_splitter.create_documents([text])</span></span></code></pre></div><h2 id="_4-文档特定拆分" tabindex="-1">4. 文档特定拆分 <a class="header-anchor" href="#_4-文档特定拆分" aria-label="Permalink to &quot;4. 文档特定拆分&quot;">​</a></h2><p><strong>Markdown 分割</strong></p><p>Markdown 特定的分割确保基于结构标记（如标题或列表）的逻辑分组。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>splitter = MarkdownTextSplitter(chunk_size=40, chunk_overlap=0)</span></span>
<span class="line"><span>documents = splitter.create_documents([markdown_text])</span></span></code></pre></div><p><strong>代码拆分</strong></p><p>编程语言如 Python 和 JavaScript 根据语法进行划分，以保持功能性和可读性。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>python_splitter = PythonCodeTextSplitter(chunk_size=100)</span></span>
<span class="line"><span>documents = python_splitter.create_documents([python_text])</span></span></code></pre></div><h2 id="_5-高级语义分块" tabindex="-1">5. 高级语义分块 <a class="header-anchor" href="#_5-高级语义分块" aria-label="Permalink to &quot;5. 高级语义分块&quot;">​</a></h2><p>语义分块使用嵌入来计算句子之间的语义相似度，并根据预定义的阈值（例如，百分位数）进行分割。这确保了块在意义上被有意义地分隔。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from langchain_experimental.text_splitter import SemanticChunker</span></span>
<span class="line"><span>text_splitter = SemanticChunker(OpenAIEmbeddings(), breakpoint_threshold_type=&quot;percentile&quot;)</span></span>
<span class="line"><span>documents = text_splitter.create_documents([text])</span></span></code></pre></div><h2 id="_6-代理分块" tabindex="-1">6. 代理分块 <a class="header-anchor" href="#_6-代理分块" aria-label="Permalink to &quot;6. 代理分块&quot;">​</a></h2><p>代理分块引入了基于命题的分块方法，其中句子或命题通过基于LLM的处理流程提取。这些命题使用<code>AgenticChunker</code>逻辑分组。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from agentic_chunker import AgenticChunker</span></span>
<span class="line"><span>ac = AgenticChunker()</span></span>
<span class="line"><span>ac.add_propositions(text_propositions)</span></span>
<span class="line"><span>chunks = ac.get_chunks(get_type=&#39;list_of_strings&#39;)</span></span>
<span class="line"><span>documents = [Document(page_content=chunk, metadata={&quot;source&quot;: &quot;local&quot;}) for chunk in chunks]</span></span></code></pre></div><h1 id="执行" tabindex="-1">执行 <a class="header-anchor" href="#执行" aria-label="Permalink to &quot;执行&quot;">​</a></h1><p>代码最终将上述所有策略集成到一个 RAG 管道中。文本分割准备数据，而 RAG 函数使基于分割文档的问答变得高效。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>rag(documents, &quot;agentic-chunks&quot;)</span></span></code></pre></div><h1 id="实施优势" tabindex="-1">实施优势 <a class="header-anchor" href="#实施优势" aria-label="Permalink to &quot;实施优势&quot;">​</a></h1><ol><li>可扩展性：LangChain 的文本拆分技术的模块化支持各种文档格式和用例。</li><li>精度：先进的分割策略，如语义和代理分块，确保高质量的分段。</li><li>与 RAG 集成：直接集成到基于检索的工作流程中，以增强性能。</li></ol><p>参考：<a href="https://medium.com/@danushidk507/chunking-strategies-f93dbdec7634" target="_blank" rel="noreferrer">https://medium.com/@danushidk507/chunking-strategies-f93dbdec7634</a></p><h2 id="联系我" tabindex="-1">联系我 <a class="header-anchor" href="#联系我" aria-label="Permalink to &quot;联系我&quot;">​</a></h2><p>最后，推荐大家关注一下开源项目：LangChat，Java生态下的AIGC大模型产品解决方案。</p><ul><li>LangChat产品官网：<a href="https://langchat.cn/" target="_blank" rel="noreferrer">https://langchat.cn/</a></li><li>Github: <a href="https://github.com/TyCoding/langchat" target="_blank" rel="noreferrer">https://github.com/TyCoding/langchat</a></li><li>Gitee: <a href="https://gitee.com/langchat/langchat" target="_blank" rel="noreferrer">https://gitee.com/langchat/langchat</a></li><li>微信：LangchainChat</li></ul><p><img src="http://cdn.tycoding.cn/docs/202502151026673.png" alt="" loading="lazy"></p>`,230)]))}const g=n(i,[["render",t]]);export{d as __pageData,g as default};
